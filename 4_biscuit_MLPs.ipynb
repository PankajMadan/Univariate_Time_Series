{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "executed-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Python Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sacred-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 72 entries, 2016-10-01 to 2019-09-01\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Vol       72 non-null     float64\n",
      " 1   Category  72 non-null     object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reading in the dataset & getting its info\n",
    "df = pd.read_csv('prepared_data.csv',index_col='Date',parse_dates=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregating the dataset for buiscuits and Chocolate\n",
    "bis = df.loc[df['Category'] == 'BISCUIT']\n",
    "choc = df.loc[df['Category'] != 'BISCUIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dominant-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing keras from tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-bracelet",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "### 1) As we observed earlier log_biscuit_volume series is Non-Stationary. lets see if we can make it stationary by taking diffrence of order = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stopped-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the biscuit volume series into pandas series\n",
    "bis_s = (bis['Vol']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "earned-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking log of the biscuit volume series to reduce variance\n",
    "bis_log = np.log10(bis_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "taken-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the difference = 1 of the log series & removing nan values\n",
    "bis_log_diff = (bis_log.diff(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unexpected-tucson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bis_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ideal-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the log biscuit  differenced series of order 1\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(bis_log_diff,color='blue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Diff_log_Volume_Sold')\n",
    "plt.title('Plot of order=1 differenced log_biscuit series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-support",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "### 1) The above series appears to be stationary. but we need to further apply statistical test to check for unit root stationarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-monitor",
   "metadata": {},
   "source": [
    "### Running Stationarity tests on the differenced series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mature-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to test for stationarity  of the seasonally differenced series using KPSS test\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "def kpss_test(timeseries):\n",
    "    print ('Results of KPSS Test:')\n",
    "    kpsstest = kpss(timeseries, regression='c', nlags=\"auto\")\n",
    "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','Lags Used'])\n",
    "    #kpss_output\n",
    "    for key,value in kpsstest[3].items():\n",
    "        kpss_output['Critical Value (%s)'%key] = value\n",
    "    print (kpss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informed-helena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of KPSS Test:\n",
      "Test Statistic            0.500000\n",
      "p-value                   0.041667\n",
      "Lags Used                34.000000\n",
      "Critical Value (10%)      0.347000\n",
      "Critical Value (5%)       0.463000\n",
      "Critical Value (2.5%)     0.574000\n",
      "Critical Value (1%)       0.739000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Applying KPSS test to check for unit root of the bis_log_diff series\n",
    "kpss_test(bis_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sitting-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to test for stationarity  of the seasonally differenced series using adf test test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(timeseries):\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "       dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mechanical-curve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Dickey-Fuller Test:\n",
      "Test Statistic                -5.910176e+00\n",
      "p-value                        2.650256e-07\n",
      "#Lags Used                     4.000000e+00\n",
      "Number of Observations Used    3.000000e+01\n",
      "Critical Value (1%)           -3.669920e+00\n",
      "Critical Value (5%)           -2.964071e+00\n",
      "Critical Value (10%)          -2.621171e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Applying adf test to check for unit root of the bis_log_diff series\n",
    "adf_test(bis_log_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-instruction",
   "metadata": {},
   "source": [
    "### Observations: \n",
    "### 1) From the above tests it appears that series is more or less stationary. Lets try to plot its ACF & PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "formal-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the acf of the differenced log biscuit series\n",
    "import statsmodels.api as sm\n",
    "sm.graphics.tsa.plot_acf(bis_log_diff, lags=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "political-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the pacf of the differenced log biscuit series\n",
    "sm.graphics.tsa.plot_pacf(bis_log_diff, lags=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-region",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "### 1) The above plots also reveal that differenced log_bis series is stationary.\n",
    "### 2) The PACF plots show that 5 lags may be useful as features for predicting the present values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "round-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform series into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "    ''' Transform a time series to a training and the test set'''\n",
    "    df = pd.DataFrame(data)\n",
    "    cols = list()\n",
    "# input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "# forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "# put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "# drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.iloc[:,:-n_out] , agg.iloc[:,-n_out:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "peripheral-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting bis_log_diff series to the X_train & y_train with lag 5 values as features\n",
    "X, y = series_to_supervised(bis_log_diff, n_in=5, n_out=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "certified-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns of the X_train\n",
    "X.columns = ['Lag_5', 'Lag_4', 'Lag_3', 'Lag_2', 'Lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "attempted-teaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag_5</th>\n",
       "      <th>Lag_4</th>\n",
       "      <th>Lag_3</th>\n",
       "      <th>Lag_2</th>\n",
       "      <th>Lag_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>-0.146061</td>\n",
       "      <td>-0.001623</td>\n",
       "      <td>0.101295</td>\n",
       "      <td>0.050263</td>\n",
       "      <td>0.014381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>-0.001623</td>\n",
       "      <td>0.101295</td>\n",
       "      <td>0.050263</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>-0.084196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-01</th>\n",
       "      <td>0.101295</td>\n",
       "      <td>0.050263</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>-0.084196</td>\n",
       "      <td>0.068877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01</th>\n",
       "      <td>0.050263</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>-0.084196</td>\n",
       "      <td>0.068877</td>\n",
       "      <td>-0.086267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>0.014381</td>\n",
       "      <td>-0.084196</td>\n",
       "      <td>0.068877</td>\n",
       "      <td>-0.086267</td>\n",
       "      <td>0.150211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>-0.084196</td>\n",
       "      <td>0.068877</td>\n",
       "      <td>-0.086267</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>-0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>0.068877</td>\n",
       "      <td>-0.086267</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>0.047680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>-0.086267</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>0.047680</td>\n",
       "      <td>-0.133896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>0.150211</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>0.047680</td>\n",
       "      <td>-0.133896</td>\n",
       "      <td>0.093957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>-0.001160</td>\n",
       "      <td>0.047680</td>\n",
       "      <td>-0.133896</td>\n",
       "      <td>0.093957</td>\n",
       "      <td>0.014633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>0.047680</td>\n",
       "      <td>-0.133896</td>\n",
       "      <td>0.093957</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.038167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>-0.133896</td>\n",
       "      <td>0.093957</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.038167</td>\n",
       "      <td>-0.125561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.093957</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.038167</td>\n",
       "      <td>-0.125561</td>\n",
       "      <td>0.068066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.038167</td>\n",
       "      <td>-0.125561</td>\n",
       "      <td>0.068066</td>\n",
       "      <td>0.032099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>0.038167</td>\n",
       "      <td>-0.125561</td>\n",
       "      <td>0.068066</td>\n",
       "      <td>0.032099</td>\n",
       "      <td>0.017765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-01</th>\n",
       "      <td>-0.125561</td>\n",
       "      <td>0.068066</td>\n",
       "      <td>0.032099</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>-0.081216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01</th>\n",
       "      <td>0.068066</td>\n",
       "      <td>0.032099</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>-0.081216</td>\n",
       "      <td>0.111959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01</th>\n",
       "      <td>0.032099</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>-0.081216</td>\n",
       "      <td>0.111959</td>\n",
       "      <td>0.029550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>0.017765</td>\n",
       "      <td>-0.081216</td>\n",
       "      <td>0.111959</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>-0.058118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>-0.081216</td>\n",
       "      <td>0.111959</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>-0.058118</td>\n",
       "      <td>0.050459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>0.111959</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>-0.058118</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>-0.086230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>0.029550</td>\n",
       "      <td>-0.058118</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>-0.086230</td>\n",
       "      <td>0.026412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>-0.058118</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>-0.086230</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.193209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>0.050459</td>\n",
       "      <td>-0.086230</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.193209</td>\n",
       "      <td>-0.092897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>-0.086230</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.193209</td>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.193209</td>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>0.193209</td>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.117007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.117007</td>\n",
       "      <td>0.121464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.117007</td>\n",
       "      <td>0.121464</td>\n",
       "      <td>0.073344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Lag_5     Lag_4     Lag_3     Lag_2     Lag_1\n",
       "Date                                                        \n",
       "2017-04-01 -0.146061 -0.001623  0.101295  0.050263  0.014381\n",
       "2017-05-01 -0.001623  0.101295  0.050263  0.014381 -0.084196\n",
       "2017-06-01  0.101295  0.050263  0.014381 -0.084196  0.068877\n",
       "2017-07-01  0.050263  0.014381 -0.084196  0.068877 -0.086267\n",
       "2017-08-01  0.014381 -0.084196  0.068877 -0.086267  0.150211\n",
       "2017-09-01 -0.084196  0.068877 -0.086267  0.150211 -0.001160\n",
       "2017-10-01  0.068877 -0.086267  0.150211 -0.001160  0.047680\n",
       "2017-11-01 -0.086267  0.150211 -0.001160  0.047680 -0.133896\n",
       "2017-12-01  0.150211 -0.001160  0.047680 -0.133896  0.093957\n",
       "2018-01-01 -0.001160  0.047680 -0.133896  0.093957  0.014633\n",
       "2018-02-01  0.047680 -0.133896  0.093957  0.014633  0.038167\n",
       "2018-03-01 -0.133896  0.093957  0.014633  0.038167 -0.125561\n",
       "2018-04-01  0.093957  0.014633  0.038167 -0.125561  0.068066\n",
       "2018-05-01  0.014633  0.038167 -0.125561  0.068066  0.032099\n",
       "2018-06-01  0.038167 -0.125561  0.068066  0.032099  0.017765\n",
       "2018-07-01 -0.125561  0.068066  0.032099  0.017765 -0.081216\n",
       "2018-08-01  0.068066  0.032099  0.017765 -0.081216  0.111959\n",
       "2018-09-01  0.032099  0.017765 -0.081216  0.111959  0.029550\n",
       "2018-10-01  0.017765 -0.081216  0.111959  0.029550 -0.058118\n",
       "2018-11-01 -0.081216  0.111959  0.029550 -0.058118  0.050459\n",
       "2018-12-01  0.111959  0.029550 -0.058118  0.050459 -0.086230\n",
       "2019-01-01  0.029550 -0.058118  0.050459 -0.086230  0.026412\n",
       "2019-02-01 -0.058118  0.050459 -0.086230  0.026412  0.193209\n",
       "2019-03-01  0.050459 -0.086230  0.026412  0.193209 -0.092897\n",
       "2019-04-01 -0.086230  0.026412  0.193209 -0.092897 -0.029432\n",
       "2019-05-01  0.026412  0.193209 -0.092897 -0.029432  0.021367\n",
       "2019-06-01  0.193209 -0.092897 -0.029432  0.021367  0.044184\n",
       "2019-07-01 -0.092897 -0.029432  0.021367  0.044184 -0.117007\n",
       "2019-08-01 -0.029432  0.021367  0.044184 -0.117007  0.121464\n",
       "2019-09-01  0.021367  0.044184 -0.117007  0.121464  0.073344"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "driven-montana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-bradford",
   "metadata": {},
   "source": [
    "### In keeping with the SARIMA analysis, lets keep 6 observations in the test set, 4 in the validation & 20 in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "changed-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the observations into training & test set\n",
    "X_train, X_test = X.iloc[:24], X.iloc[24:]\n",
    "y_train, y_test = y.iloc[:24], y.iloc[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "informational-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training set  into training & validation set\n",
    "X_train, X_val = X_train.iloc[:20], X_train.iloc[20:]\n",
    "y_train, y_val = y_train.iloc[:20], y_train.iloc[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "liable-aquatic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_val),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prompt-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing hyperparameter tuning library Optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "becoming-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-trading",
   "metadata": {},
   "source": [
    "### Tuning hyper-parameters of the MLP Neural Net using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "saved-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the objective function\n",
    "def objective_wrappper_keras_eq(X_tr, y_tr, X_val, y_val):\n",
    "    '''\n",
    "    Optimizes Keras neural net(with equal no. of neurons in each layer) best parameters \n",
    "    on the given training set: X_tr, y_tr using validation set: X_val,y_val \n",
    "    \n",
    "    '''\n",
    "    def objective(trial):\n",
    "        # Tuning the learning rate\n",
    "        s = trial.suggest_int('step',2,5)\n",
    "        def exponential_decay_fn(epoch): # \n",
    "            return 0.01 * 0.1**(epoch /s )     \n",
    "        \n",
    "        # Building model & searching for the best no. of neural units per layer.\n",
    "        no_units = trial.suggest_int('no._units',100,500)# No. of Neurons in each layer\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.InputLayer(input_shape=X_tr.shape[1:]))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dense(units=no_units,activation='selu',\n",
    "                                     kernel_initializer='lecun_normal')) # For self normalization\n",
    "        #model.add(keras.layers.Dense(units=no_units,activation='selu',\n",
    "                                     #kernel_initializer='lecun_normal'))\n",
    "        model.add(keras.layers.Dense(units=1))\n",
    "    \n",
    "            \n",
    "        # Compiling the model\n",
    "        model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Nadam(beta_1=0.9, beta_2=0.999)\n",
    "                      ,metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "        # Defining the Callbacks\n",
    "        checkpoint_cb = keras.callbacks.ModelCheckpoint('best_model.h5',save_best_only=True) # 1st Callback\n",
    "        early_stopping_cb = keras.callbacks.EarlyStopping(patience=30,restore_best_weights=True) # 2nd Callback, Stop if validation score doen't improve for\n",
    "        # 30 epochs        \n",
    "        lr_scheduler_cb = keras.callbacks.LearningRateScheduler(exponential_decay_fn)# 3rd Callback\n",
    "        \n",
    "        #Fitting the model\n",
    "        model.fit(X_tr, y_tr, epochs=200, validation_data=(X_val,y_val), batch_size=4,\n",
    "             callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler_cb], shuffle=False)\n",
    "    \n",
    "        # Loading the best model \n",
    "        model_best = keras.models.load_model('best_model.h5')\n",
    "    \n",
    "        # Computing the roc_auc_score for the validation set\n",
    "        error = sqrt(mean_squared_error(y_val, model_best.predict(X_val)))\n",
    "        global best_error\n",
    "        # Updating best_error score\n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            model_best.save('Best_model_Selu_eq_Learn.h5')\n",
    "        \n",
    "        return error\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "resident-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the evaluation function for study's best parameters\n",
    "def study_func(X_tr, y_tr, X_v, y_v, obj_func, n_trials=200):\n",
    "    ''' Computes the best hyper parameters of the Neural net using the Training set(X_tr,y_tr) & Validation set\n",
    "    (X_v,y_v) & returns Optuna's study's best score & clasifier parameters'''\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(obj_func(X_tr, y_tr, X_v, y_v), n_trials)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "    return (best_score, best_params)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "advised-promotion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:05,710]\u001b[0m A new study created in memory with name: no-name-b2fd05e2-7981-4b50-9cf3-16491f17745a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1649 - root_mean_squared_error: 0.4061 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - root_mean_squared_error: 0.2479 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - root_mean_squared_error: 0.1003 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - root_mean_squared_error: 0.0658 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1217\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - root_mean_squared_error: 0.0633 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1208\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0038 - root_mean_squared_error: 0.0616 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0037 - root_mean_squared_error: 0.0606 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0036 - root_mean_squared_error: 0.0599 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0035 - root_mean_squared_error: 0.0594 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - root_mean_squared_error: 0.0592 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AED14550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:09,515]\u001b[0m Trial 0 finished with value: 0.07733891168400031 and parameters: {'step': 5, 'no._units': 135}. Best is trial 0 with value: 0.07733891168400031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4437 - root_mean_squared_error: 0.6661 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0155 - root_mean_squared_error: 0.1247 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0138 - root_mean_squared_error: 0.1175 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0130 - root_mean_squared_error: 0.1138 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0125 - root_mean_squared_error: 0.1120 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0122 - root_mean_squared_error: 0.1102 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1102 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BA594160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:11,609]\u001b[0m Trial 1 finished with value: 0.09135437592163195 and parameters: {'step': 3, 'no._units': 162}. Best is trial 0 with value: 0.07733891168400031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0844 - root_mean_squared_error: 0.2905WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5800 - root_mean_squared_error: 1.2570 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2437 - root_mean_squared_error: 0.4937 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1589 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1423 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0174 - root_mean_squared_error: 0.1319 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0170 - root_mean_squared_error: 0.1303 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0168 - root_mean_squared_error: 0.1295 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1288 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BD706C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:15,236]\u001b[0m Trial 2 finished with value: 0.09167269459950612 and parameters: {'step': 3, 'no._units': 429}. Best is trial 0 with value: 0.07733891168400031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3670 - root_mean_squared_error: 0.6058 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0784 - root_mean_squared_error: 0.2800 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0230 - root_mean_squared_error: 0.1515 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1213 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - root_mean_squared_error: 0.1139 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1086 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - root_mean_squared_error: 0.1050 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1026 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - root_mean_squared_error: 0.1010 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - root_mean_squared_error: 0.1000 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0993 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - root_mean_squared_error: 0.0989 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - root_mean_squared_error: 0.0985 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - root_mean_squared_error: 0.0983 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - root_mean_squared_error: 0.0983 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0982 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0982 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0982 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1158\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BBD40940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:16,811]\u001b[0m Trial 3 finished with value: 0.11511361426860738 and parameters: {'step': 5, 'no._units': 156}. Best is trial 0 with value: 0.07733891168400031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9932 - root_mean_squared_error: 1.4118 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1004 - root_mean_squared_error: 0.3168 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0394 - root_mean_squared_error: 0.1986 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0318 - root_mean_squared_error: 0.1783 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0293 - root_mean_squared_error: 0.1710 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0290 - root_mean_squared_error: 0.1704 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0290 - root_mean_squared_error: 0.1702 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0704\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0644\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0654\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0670\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1701 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B4AF1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:19,440]\u001b[0m Trial 4 finished with value: 0.06293740092760802 and parameters: {'step': 2, 'no._units': 488}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.8656 - root_mean_squared_error: 0.9304 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1821 - root_mean_squared_error: 0.4267 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0820 - root_mean_squared_error: 0.2863 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0520 - root_mean_squared_error: 0.2281 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0403 - root_mean_squared_error: 0.2009 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0349 - root_mean_squared_error: 0.1869 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0322 - root_mean_squared_error: 0.1794 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0307 - root_mean_squared_error: 0.1752 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0294 - root_mean_squared_error: 0.1715 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0291 - root_mean_squared_error: 0.1707 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0290 - root_mean_squared_error: 0.1702 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1698 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0288 - root_mean_squared_error: 0.1697 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0877\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0875\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BF284700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:21,884]\u001b[0m Trial 5 finished with value: 0.0870192287720652 and parameters: {'step': 4, 'no._units': 286}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4612 - root_mean_squared_error: 0.6791 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0770 - root_mean_squared_error: 0.2774 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1338\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0361 - root_mean_squared_error: 0.1901 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0214 - root_mean_squared_error: 0.1462 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0158 - root_mean_squared_error: 0.1255 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0133 - root_mean_squared_error: 0.1152 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1097 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0110 - root_mean_squared_error: 0.1051 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0108 - root_mean_squared_error: 0.1041 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0107 - root_mean_squared_error: 0.1035 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0107 - root_mean_squared_error: 0.1032 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1030 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1029 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1029 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE7AB3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:25,964]\u001b[0m Trial 6 finished with value: 0.09103329414805315 and parameters: {'step': 4, 'no._units': 117}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1649 - root_mean_squared_error: 1.4714 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0738 - root_mean_squared_error: 0.2716 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1626\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0160 - root_mean_squared_error: 0.1267 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1597\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0127 - root_mean_squared_error: 0.1125 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - root_mean_squared_error: 0.1066 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1594\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - root_mean_squared_error: 0.1040 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1598\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1604\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1023 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1020 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1616\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1019 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1622\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1018 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1628\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1018 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1635\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1018 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1641\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1649\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1656\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1663\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1677\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1699\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1721\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1752\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1760\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1775\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1791\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1017 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1798\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020290ACEF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:27,634]\u001b[0m Trial 7 finished with value: 0.15921407185831724 and parameters: {'step': 3, 'no._units': 453}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4696 - root_mean_squared_error: 0.6853 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0580 - root_mean_squared_error: 0.2409 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0242 - root_mean_squared_error: 0.1554 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1392 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - root_mean_squared_error: 0.1342 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - root_mean_squared_error: 0.1326 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1319 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1217\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028D848160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:29,298]\u001b[0m Trial 8 finished with value: 0.10772298909666994 and parameters: {'step': 2, 'no._units': 178}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6304 - root_mean_squared_error: 0.7940 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2070 - root_mean_squared_error: 0.4549 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2280\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - root_mean_squared_error: 0.1525 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2409\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - root_mean_squared_error: 0.1250 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2423\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1221 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - root_mean_squared_error: 0.1206 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2431\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1199 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2432\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - root_mean_squared_error: 0.1195 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2432\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1193 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2431\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1192 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2430\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1192 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2428\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2426\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2425\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2423\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2421\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2420\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0585 - val_root_mean_squared_error: 0.2418\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2416\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0583 - val_root_mean_squared_error: 0.2414\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2412\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2408\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0579 - val_root_mean_squared_error: 0.2406\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0578 - val_root_mean_squared_error: 0.2404\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0577 - val_root_mean_squared_error: 0.2402\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2399\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0575 - val_root_mean_squared_error: 0.2397\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0573 - val_root_mean_squared_error: 0.2394\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0572 - val_root_mean_squared_error: 0.2391\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C060D940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:30,795]\u001b[0m Trial 9 finished with value: 0.1949460946710935 and parameters: {'step': 3, 'no._units': 224}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7440 - root_mean_squared_error: 0.8626 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2469\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2209 - root_mean_squared_error: 0.4700 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - root_mean_squared_error: 0.0860 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2468\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0066 - root_mean_squared_error: 0.0813 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2476\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2481\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0793 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2487\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0791 - val_loss: 0.0621 - val_root_mean_squared_error: 0.2492\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0624 - val_root_mean_squared_error: 0.2497\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0626 - val_root_mean_squared_error: 0.2502\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2508\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2513\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0634 - val_root_mean_squared_error: 0.2518\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2523\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2528\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0641 - val_root_mean_squared_error: 0.2532\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0645 - val_root_mean_squared_error: 0.2540\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0647 - val_root_mean_squared_error: 0.2544\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0654 - val_root_mean_squared_error: 0.2557\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0656 - val_root_mean_squared_error: 0.2561\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2565\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0660 - val_root_mean_squared_error: 0.2569\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0662 - val_root_mean_squared_error: 0.2574\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2578\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2582\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0668 - val_root_mean_squared_error: 0.2585\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0670 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0671 - val_root_mean_squared_error: 0.2591\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0673 - val_root_mean_squared_error: 0.2594\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B1A5D670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:32,336]\u001b[0m Trial 10 finished with value: 0.2444740591868339 and parameters: {'step': 2, 'no._units': 377}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1681 - root_mean_squared_error: 1.0808 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1979\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1215 - root_mean_squared_error: 0.3486 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1393\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0543 - root_mean_squared_error: 0.2330 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0291 - root_mean_squared_error: 0.1705 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0188 - root_mean_squared_error: 0.1370 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1327\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0119 - root_mean_squared_error: 0.1091 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1324\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1032 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1319\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0996 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0095 - root_mean_squared_error: 0.0974 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0092 - root_mean_squared_error: 0.0960 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0090 - root_mean_squared_error: 0.0951 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1302\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0088 - root_mean_squared_error: 0.0939 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0088 - root_mean_squared_error: 0.0938 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0088 - root_mean_squared_error: 0.0937 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1284\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0088 - root_mean_squared_error: 0.0936 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0088 - root_mean_squared_error: 0.0936 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1214\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1305\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1362\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1421\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1605\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1798\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1863\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1928\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1993\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2058\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2123\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0479 - val_root_mean_squared_error: 0.2188\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B33778B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:36,457]\u001b[0m Trial 11 finished with value: 0.08112232495285221 and parameters: {'step': 5, 'no._units': 338}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1686 - root_mean_squared_error: 1.4726 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3415 - root_mean_squared_error: 0.5844 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0217 - root_mean_squared_error: 0.1473 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0946 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - root_mean_squared_error: 0.0884 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0064 - root_mean_squared_error: 0.0803 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0792 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0785 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0775 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0774 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B2DFC160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:38,122]\u001b[0m Trial 12 finished with value: 0.08694305283705299 and parameters: {'step': 5, 'no._units': 494}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6109 - root_mean_squared_error: 0.7816 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2250\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0663 - root_mean_squared_error: 0.2576 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2024\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1849\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0085 - root_mean_squared_error: 0.0924 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1799\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0065 - root_mean_squared_error: 0.0805 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0049 - root_mean_squared_error: 0.0701 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0047 - root_mean_squared_error: 0.0685 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0681 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1725\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0679 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1717\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1700\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1675\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1658\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1649\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1641\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1623\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1603\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1594\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1553\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1521\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1500\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1468\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1446\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1436\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1363\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1354\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1335\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1360\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1462\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1598\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1628\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1659\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1725\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1793\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B7435430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:41,807]\u001b[0m Trial 13 finished with value: 0.12581061325673068 and parameters: {'step': 4, 'no._units': 276}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3425 - root_mean_squared_error: 0.5853 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0586 - root_mean_squared_error: 0.2420 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0401 - root_mean_squared_error: 0.2002 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0344 - root_mean_squared_error: 0.1853 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0325 - root_mean_squared_error: 0.1802 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0318 - root_mean_squared_error: 0.1784 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1776 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1152\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - root_mean_squared_error: 0.1775 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1202\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020299A5B820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:43,422]\u001b[0m Trial 14 finished with value: 0.11401060475045013 and parameters: {'step': 2, 'no._units': 110}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7119 - root_mean_squared_error: 1.3084 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2452 - root_mean_squared_error: 0.4952 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0477 - root_mean_squared_error: 0.2185 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0260 - root_mean_squared_error: 0.1614 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1495 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1357 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1350 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1348 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1347 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1319\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1323\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1338\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1342\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1351\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1360\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1364\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1385\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1392\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A3C74D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:44,998]\u001b[0m Trial 15 finished with value: 0.1227771842672943 and parameters: {'step': 4, 'no._units': 240}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5356 - root_mean_squared_error: 1.2392 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2172\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5279 - root_mean_squared_error: 0.7266 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0917 - root_mean_squared_error: 0.3028 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - root_mean_squared_error: 0.2223 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0262 - root_mean_squared_error: 0.1620 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0168 - root_mean_squared_error: 0.1298 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1130 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - root_mean_squared_error: 0.1038 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0934 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0922 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0914 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0905 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0900 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0900 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0900 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1237\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1231\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1231\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1243\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1282\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1302\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029C6EBC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:47,397]\u001b[0m Trial 16 finished with value: 0.12213947326881376 and parameters: {'step': 5, 'no._units': 396}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9469 - root_mean_squared_error: 1.3953 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8575 - root_mean_squared_error: 0.9260 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1062 - root_mean_squared_error: 0.3259 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0627 - root_mean_squared_error: 0.2504 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0537 - root_mean_squared_error: 0.2316 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0510 - root_mean_squared_error: 0.2259 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - root_mean_squared_error: 0.2241 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0499 - root_mean_squared_error: 0.2235 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C30B0700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:48,953]\u001b[0m Trial 17 finished with value: 0.07774915262183889 and parameters: {'step': 2, 'no._units': 487}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3777 - root_mean_squared_error: 1.1738 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1313\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3636 - root_mean_squared_error: 0.6030 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0497 - root_mean_squared_error: 0.2230 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1690 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1520 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0202 - root_mean_squared_error: 0.1422 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1408 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1402 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0820\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0815\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE4FA550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:51,939]\u001b[0m Trial 18 finished with value: 0.08059444089763156 and parameters: {'step': 3, 'no._units': 352}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9723 - root_mean_squared_error: 0.9861 - val_loss: 0.2089 - val_root_mean_squared_error: 0.4570\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2435 - root_mean_squared_error: 0.4934 - val_loss: 0.1429 - val_root_mean_squared_error: 0.3780\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.1189 - val_root_mean_squared_error: 0.3449\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0239 - root_mean_squared_error: 0.1547 - val_loss: 0.1092 - val_root_mean_squared_error: 0.3305\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0193 - root_mean_squared_error: 0.1390 - val_loss: 0.1047 - val_root_mean_squared_error: 0.3235\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.1024 - val_root_mean_squared_error: 0.3200\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.1011 - val_root_mean_squared_error: 0.3180\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0153 - root_mean_squared_error: 0.1236 - val_loss: 0.1004 - val_root_mean_squared_error: 0.3169\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.1000 - val_root_mean_squared_error: 0.3162\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1213 - val_loss: 0.0997 - val_root_mean_squared_error: 0.3158\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209 - val_loss: 0.0995 - val_root_mean_squared_error: 0.3154\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0145 - root_mean_squared_error: 0.1206 - val_loss: 0.0993 - val_root_mean_squared_error: 0.3152\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0145 - root_mean_squared_error: 0.1204 - val_loss: 0.0992 - val_root_mean_squared_error: 0.3150\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0145 - root_mean_squared_error: 0.1203 - val_loss: 0.0991 - val_root_mean_squared_error: 0.3148\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0145 - root_mean_squared_error: 0.1203 - val_loss: 0.0990 - val_root_mean_squared_error: 0.3147\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0145 - root_mean_squared_error: 0.1202 - val_loss: 0.0989 - val_root_mean_squared_error: 0.3145\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0145 - root_mean_squared_error: 0.1202 - val_loss: 0.0988 - val_root_mean_squared_error: 0.3143\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0987 - val_root_mean_squared_error: 0.3141\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0986 - val_root_mean_squared_error: 0.3139\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0984 - val_root_mean_squared_error: 0.3137\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0983 - val_root_mean_squared_error: 0.3136\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0982 - val_root_mean_squared_error: 0.3134\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0981 - val_root_mean_squared_error: 0.3132\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0980 - val_root_mean_squared_error: 0.3130\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0979 - val_root_mean_squared_error: 0.3129\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0978 - val_root_mean_squared_error: 0.3127\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0976 - val_root_mean_squared_error: 0.3125\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0975 - val_root_mean_squared_error: 0.3123\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0974 - val_root_mean_squared_error: 0.3121\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0973 - val_root_mean_squared_error: 0.3119\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0972 - val_root_mean_squared_error: 0.3117\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0970 - val_root_mean_squared_error: 0.3115\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0969 - val_root_mean_squared_error: 0.3113\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0967 - val_root_mean_squared_error: 0.3110\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0966 - val_root_mean_squared_error: 0.3108\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0965 - val_root_mean_squared_error: 0.3106\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0963 - val_root_mean_squared_error: 0.3104\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0962 - val_root_mean_squared_error: 0.3102\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0961 - val_root_mean_squared_error: 0.3100\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0960 - val_root_mean_squared_error: 0.3098\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0959 - val_root_mean_squared_error: 0.3096\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0957 - val_root_mean_squared_error: 0.3094\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0956 - val_root_mean_squared_error: 0.3092\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0955 - val_root_mean_squared_error: 0.3090\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0954 - val_root_mean_squared_error: 0.3088\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0953 - val_root_mean_squared_error: 0.3087\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0952 - val_root_mean_squared_error: 0.3085\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0951 - val_root_mean_squared_error: 0.3083\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0950 - val_root_mean_squared_error: 0.3082\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0949 - val_root_mean_squared_error: 0.3080\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0948 - val_root_mean_squared_error: 0.3079\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0947 - val_root_mean_squared_error: 0.3077\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0946 - val_root_mean_squared_error: 0.3076\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0946 - val_root_mean_squared_error: 0.3075\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0945 - val_root_mean_squared_error: 0.3074\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0945 - val_root_mean_squared_error: 0.3073\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3073\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3072\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3072\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3072\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3072\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0944 - val_root_mean_squared_error: 0.3073\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0945 - val_root_mean_squared_error: 0.3074\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0945 - val_root_mean_squared_error: 0.3075\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0946 - val_root_mean_squared_error: 0.3076\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0948 - val_root_mean_squared_error: 0.3078\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0949 - val_root_mean_squared_error: 0.3081\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0951 - val_root_mean_squared_error: 0.3084\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0953 - val_root_mean_squared_error: 0.3087\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0955 - val_root_mean_squared_error: 0.3090\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0958 - val_root_mean_squared_error: 0.3095\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0961 - val_root_mean_squared_error: 0.3099\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0964 - val_root_mean_squared_error: 0.3105\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0967 - val_root_mean_squared_error: 0.3110\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0971 - val_root_mean_squared_error: 0.3117\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0976 - val_root_mean_squared_error: 0.3124\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0980 - val_root_mean_squared_error: 0.3131\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0986 - val_root_mean_squared_error: 0.3139\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0991 - val_root_mean_squared_error: 0.3148\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0997 - val_root_mean_squared_error: 0.3158\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1003 - val_root_mean_squared_error: 0.3168\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1010 - val_root_mean_squared_error: 0.3178\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1018 - val_root_mean_squared_error: 0.3190\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1025 - val_root_mean_squared_error: 0.3202\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1034 - val_root_mean_squared_error: 0.3215\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1042 - val_root_mean_squared_error: 0.3228\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1051 - val_root_mean_squared_error: 0.3243\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1061 - val_root_mean_squared_error: 0.3258\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1071 - val_root_mean_squared_error: 0.3273\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.1082 - val_root_mean_squared_error: 0.3289\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B1A5D940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:55,391]\u001b[0m Trial 19 finished with value: 0.30719170923426276 and parameters: {'step': 4, 'no._units': 320}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6534 - root_mean_squared_error: 0.8083 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0311 - root_mean_squared_error: 0.1764 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1343\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1250 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - root_mean_squared_error: 0.1201 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - root_mean_squared_error: 0.1167 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - root_mean_squared_error: 0.1145 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1131 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - root_mean_squared_error: 0.1121 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - root_mean_squared_error: 0.1115 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1108 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE7AB430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:56,863]\u001b[0m Trial 20 finished with value: 0.10797286653261316 and parameters: {'step': 5, 'no._units': 212}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.0928 - root_mean_squared_error: 1.7586 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2478 - root_mean_squared_error: 0.4978 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - root_mean_squared_error: 0.1805 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0865\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0200 - root_mean_squared_error: 0.1414 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - root_mean_squared_error: 0.1327 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1302 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - root_mean_squared_error: 0.1293 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0167 - root_mean_squared_error: 0.1291 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0877\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020283EDBC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:58:58,355]\u001b[0m Trial 21 finished with value: 0.0843442050317559 and parameters: {'step': 2, 'no._units': 498}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4303 - root_mean_squared_error: 1.5589 - val_loss: 0.0769 - val_root_mean_squared_error: 0.2773\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0886 - root_mean_squared_error: 0.2977 - val_loss: 0.0787 - val_root_mean_squared_error: 0.2805\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0216 - root_mean_squared_error: 0.1470 - val_loss: 0.0749 - val_root_mean_squared_error: 0.2737\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0734 - val_root_mean_squared_error: 0.2710\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0729 - val_root_mean_squared_error: 0.2699\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0163 - root_mean_squared_error: 0.1279 - val_loss: 0.0726 - val_root_mean_squared_error: 0.2695\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0725 - val_root_mean_squared_error: 0.2693\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1268 - val_loss: 0.0725 - val_root_mean_squared_error: 0.2693\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0724 - val_root_mean_squared_error: 0.2692\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0724 - val_root_mean_squared_error: 0.2690\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0723 - val_root_mean_squared_error: 0.2689\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0722 - val_root_mean_squared_error: 0.2687\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0721 - val_root_mean_squared_error: 0.2686\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0720 - val_root_mean_squared_error: 0.2683\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0719 - val_root_mean_squared_error: 0.2682\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0718 - val_root_mean_squared_error: 0.2680\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0717 - val_root_mean_squared_error: 0.2678\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0716 - val_root_mean_squared_error: 0.2676\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0715 - val_root_mean_squared_error: 0.2674\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0714 - val_root_mean_squared_error: 0.2672\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0713 - val_root_mean_squared_error: 0.2670\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0711 - val_root_mean_squared_error: 0.2667\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0709 - val_root_mean_squared_error: 0.2663\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0707 - val_root_mean_squared_error: 0.2659\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0705 - val_root_mean_squared_error: 0.2655\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0703 - val_root_mean_squared_error: 0.2650\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0700 - val_root_mean_squared_error: 0.2646\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0698 - val_root_mean_squared_error: 0.2641\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0695 - val_root_mean_squared_error: 0.2636\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0690 - val_root_mean_squared_error: 0.2626\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0687 - val_root_mean_squared_error: 0.2621\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0684 - val_root_mean_squared_error: 0.2615\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0681 - val_root_mean_squared_error: 0.2610\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0678 - val_root_mean_squared_error: 0.2604\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0675 - val_root_mean_squared_error: 0.2598\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0672 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0669 - val_root_mean_squared_error: 0.2586\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0666 - val_root_mean_squared_error: 0.2580\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0662 - val_root_mean_squared_error: 0.2573\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2566\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0655 - val_root_mean_squared_error: 0.2559\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2551\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0647 - val_root_mean_squared_error: 0.2544\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2528\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0635 - val_root_mean_squared_error: 0.2519\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0631 - val_root_mean_squared_error: 0.2511\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2503\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2495\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2486\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2478\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2469\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2451\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2442\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2433\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2423\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2413\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0577 - val_root_mean_squared_error: 0.2403\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0572 - val_root_mean_squared_error: 0.2392\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2382\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0563 - val_root_mean_squared_error: 0.2372\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0558 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2340\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2329\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2318\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0532 - val_root_mean_squared_error: 0.2307\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0527 - val_root_mean_squared_error: 0.2295\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0522 - val_root_mean_squared_error: 0.2284\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0516 - val_root_mean_squared_error: 0.2272\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0511 - val_root_mean_squared_error: 0.2260\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0505 - val_root_mean_squared_error: 0.2248\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2236\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0495 - val_root_mean_squared_error: 0.2224\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0489 - val_root_mean_squared_error: 0.2212\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2200\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2187\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2175\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2150\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2138\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2125\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2113\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2100\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2088\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2076\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0411 - val_root_mean_squared_error: 0.2028\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2016\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2005\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1994\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1983\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1962\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1951\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1931\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1922\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1913\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1904\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1895\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1887\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1871\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1864\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1850\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1844\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1826\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1821\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1811\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1807\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1798\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1794\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1791\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1787\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1784\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1776\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1773\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1769\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1763\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1760\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1759\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1755\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1753\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1752\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1751\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1751\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1748\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1748\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1745\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1745\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1745\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0161 - root_mean_squared_error: 0.1267 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A41844C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:05,830]\u001b[0m Trial 22 finished with value: 0.1739848249296831 and parameters: {'step': 2, 'no._units': 457}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8979 - root_mean_squared_error: 1.7023 - val_loss: 0.0607 - val_root_mean_squared_error: 0.2464\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1625 - root_mean_squared_error: 0.4031 - val_loss: 0.0687 - val_root_mean_squared_error: 0.2622\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0603 - root_mean_squared_error: 0.2456 - val_loss: 0.0670 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0438 - root_mean_squared_error: 0.2094 - val_loss: 0.0657 - val_root_mean_squared_error: 0.2564\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0395 - root_mean_squared_error: 0.1987 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2551\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - root_mean_squared_error: 0.1952 - val_loss: 0.0646 - val_root_mean_squared_error: 0.2542\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2535\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0375 - root_mean_squared_error: 0.1936 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2529\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1935 - val_loss: 0.0636 - val_root_mean_squared_error: 0.2523\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0633 - val_root_mean_squared_error: 0.2517\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0630 - val_root_mean_squared_error: 0.2511\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0628 - val_root_mean_squared_error: 0.2505\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0625 - val_root_mean_squared_error: 0.2500\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2495\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0620 - val_root_mean_squared_error: 0.2491\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2487\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2483\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2478\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0612 - val_root_mean_squared_error: 0.2473\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2468\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0607 - val_root_mean_squared_error: 0.2464\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2459\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0602 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2449\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2444\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0594 - val_root_mean_squared_error: 0.2438\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2432\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2426\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2420\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0583 - val_root_mean_squared_error: 0.2414\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2408\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0573 - val_root_mean_squared_error: 0.2393\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2385\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0561 - val_root_mean_squared_error: 0.2368\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2339\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2329\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2317\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0531 - val_root_mean_squared_error: 0.2305\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0526 - val_root_mean_squared_error: 0.2293\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2279\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2265\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2251\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2236\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0493 - val_root_mean_squared_error: 0.2220\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2203\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2185\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0469 - val_root_mean_squared_error: 0.2166\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2146\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2060\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2036\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1986\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1959\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1932\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1874\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1812\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1679\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1643\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1454\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1374\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0696\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0670\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1332\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A9CDF310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:10,341]\u001b[0m Trial 23 finished with value: 0.06607885861357729 and parameters: {'step': 2, 'no._units': 498}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6978 - root_mean_squared_error: 1.3030 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1892 - root_mean_squared_error: 0.4349 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1374\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0297 - root_mean_squared_error: 0.1722 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1485\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - root_mean_squared_error: 0.1284 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0163 - root_mean_squared_error: 0.1275 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1272 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1542\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B2DFC3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:11,805]\u001b[0m Trial 24 finished with value: 0.104714410093046 and parameters: {'step': 2, 'no._units': 417}. Best is trial 4 with value: 0.06293740092760802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8909 - root_mean_squared_error: 1.3751 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2915 - root_mean_squared_error: 0.5399 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1189 - root_mean_squared_error: 0.3448 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0845 - root_mean_squared_error: 0.2906 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0677 - root_mean_squared_error: 0.2601 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0601 - root_mean_squared_error: 0.2452 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0566 - root_mean_squared_error: 0.2380 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0550 - root_mean_squared_error: 0.2345 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0542 - root_mean_squared_error: 0.2328 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0538 - root_mean_squared_error: 0.2320 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0536 - root_mean_squared_error: 0.2316 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2314 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0670\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2313 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0665\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0660\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0592\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0589\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0589\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0592\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0598\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0677\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0688\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020291EAD5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:14,475]\u001b[0m Trial 25 finished with value: 0.05884030104017594 and parameters: {'step': 3, 'no._units': 465}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.0281 - root_mean_squared_error: 1.4241 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1586\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0467 - root_mean_squared_error: 0.2162 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1732\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1364 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - root_mean_squared_error: 0.1004 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1864\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - root_mean_squared_error: 0.0985 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1868\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - root_mean_squared_error: 0.0975 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1871\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0971 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1873\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1875\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0967 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1877\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0967 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1878\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1880\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1882\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1884\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1886\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1888\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1890\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1891\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1893\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1895\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1896\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1898\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1900\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1901\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1904\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1906\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1908\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1909\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1911\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B1AB3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:15,923]\u001b[0m Trial 26 finished with value: 0.15862784363889443 and parameters: {'step': 3, 'no._units': 471}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9682 - root_mean_squared_error: 1.4029 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4616 - root_mean_squared_error: 0.6794 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1431 - root_mean_squared_error: 0.3783 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1085 - root_mean_squared_error: 0.3293 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0995 - root_mean_squared_error: 0.3155 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0967 - root_mean_squared_error: 0.3110 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0958 - root_mean_squared_error: 0.3094 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0954 - root_mean_squared_error: 0.3089 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3088 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0757\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0741\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1354\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A113C550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:18,501]\u001b[0m Trial 27 finished with value: 0.06307408218027716 and parameters: {'step': 2, 'no._units': 436}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8921 - root_mean_squared_error: 1.3755 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1236 - root_mean_squared_error: 0.3516 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0506 - root_mean_squared_error: 0.2249 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0277 - root_mean_squared_error: 0.1664 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0250 - root_mean_squared_error: 0.1582 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0238 - root_mean_squared_error: 0.1542 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1523 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1509 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1506 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1506 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1219\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B7759670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:19,952]\u001b[0m Trial 28 finished with value: 0.09719957594466186 and parameters: {'step': 3, 'no._units': 432}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2246 - root_mean_squared_error: 1.1066 - val_loss: 0.0751 - val_root_mean_squared_error: 0.2741\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2053 - root_mean_squared_error: 0.4531 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1631\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0464 - root_mean_squared_error: 0.2155 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0358 - root_mean_squared_error: 0.1892 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0322 - root_mean_squared_error: 0.1793 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1757 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0304 - root_mean_squared_error: 0.1744 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0303 - root_mean_squared_error: 0.1740 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1442\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1452\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1475\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1528\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1553\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1565\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C1E2A310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:21,535]\u001b[0m Trial 29 finished with value: 0.1431878164155641 and parameters: {'step': 2, 'no._units': 388}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9381 - root_mean_squared_error: 1.3922 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2748 - root_mean_squared_error: 0.5242 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0532 - root_mean_squared_error: 0.2307 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0304 - root_mean_squared_error: 0.1742 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0235 - root_mean_squared_error: 0.1532 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0211 - root_mean_squared_error: 0.1451 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0201 - root_mean_squared_error: 0.1416 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1393 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0193 - root_mean_squared_error: 0.1389 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1387 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AB90AAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:24,814]\u001b[0m Trial 30 finished with value: 0.09349021873184873 and parameters: {'step': 3, 'no._units': 455}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4791 - root_mean_squared_error: 1.5745 - val_loss: 0.0403 - val_root_mean_squared_error: 0.2008\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5576 - root_mean_squared_error: 0.7467 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1022 - root_mean_squared_error: 0.3197 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0737 - root_mean_squared_error: 0.2715 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - root_mean_squared_error: 0.2605 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1564\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - root_mean_squared_error: 0.2571 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - root_mean_squared_error: 0.2560 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - root_mean_squared_error: 0.2556 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0653 - root_mean_squared_error: 0.2555 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1627\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1644\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1679\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1735\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1755\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1774\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1794\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1815\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1901\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1924\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1947\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1971\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2020\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2097\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2124\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0463 - val_root_mean_squared_error: 0.2151\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0475 - val_root_mean_squared_error: 0.2179\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020293A3C040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:26,372]\u001b[0m Trial 31 finished with value: 0.1553714477578347 and parameters: {'step': 2, 'no._units': 477}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4124 - root_mean_squared_error: 1.5532 - val_loss: 0.0740 - val_root_mean_squared_error: 0.2720\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3145 - root_mean_squared_error: 0.5608 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2149\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0795 - root_mean_squared_error: 0.2820 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2076\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0619 - root_mean_squared_error: 0.2488 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2056\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0566 - root_mean_squared_error: 0.2380 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2047\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0549 - root_mean_squared_error: 0.2342 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0543 - root_mean_squared_error: 0.2329 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2038\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0541 - root_mean_squared_error: 0.2325 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2034\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2324 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2029\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2025\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2021\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2018\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2014\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2010\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0403 - val_root_mean_squared_error: 0.2007\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2003\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0400 - val_root_mean_squared_error: 0.1999\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1996\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1993\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1989\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1986\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1983\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1977\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1974\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1969\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1966\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0386 - val_root_mean_squared_error: 0.1964\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1962\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1956\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1954\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1953\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1951\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1948\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1946\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1945\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1937\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1937\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1937\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1946\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1948\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1950\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1952\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1954\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1957\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1967\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1974\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1978\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1982\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1987\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1992\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0399 - val_root_mean_squared_error: 0.1997\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - root_mean_squared_error: 0.2323 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2002\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020297D5A040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:29,667]\u001b[0m Trial 32 finished with value: 0.1934238562978115 and parameters: {'step': 2, 'no._units': 494}. Best is trial 25 with value: 0.05884030104017594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9988 - root_mean_squared_error: 1.4138 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1313 - root_mean_squared_error: 0.3624 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0501 - root_mean_squared_error: 0.2238 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0391 - root_mean_squared_error: 0.1979 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0359 - root_mean_squared_error: 0.1894 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0348 - root_mean_squared_error: 0.1865 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0344 - root_mean_squared_error: 0.1856 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0343 - root_mean_squared_error: 0.1852 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0620\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0585\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0566\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0558\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0551\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0541\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0538\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0536\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0536\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0537\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0540\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0551\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0558\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0567\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0578\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0704\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0745\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - root_mean_squared_error: 0.1851 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C09813A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:32,414]\u001b[0m Trial 33 finished with value: 0.05357037665366858 and parameters: {'step': 2, 'no._units': 419}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6223 - root_mean_squared_error: 1.6193 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1319 - root_mean_squared_error: 0.3631 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0329 - root_mean_squared_error: 0.1815 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0256 - root_mean_squared_error: 0.1600 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1520 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0220 - root_mean_squared_error: 0.1482 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0214 - root_mean_squared_error: 0.1463 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1446 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1445 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1445 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1445 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - root_mean_squared_error: 0.1444 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202995FAA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:33,941]\u001b[0m Trial 34 finished with value: 0.0915936584000395 and parameters: {'step': 3, 'no._units': 439}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6064 - root_mean_squared_error: 1.2674 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1759\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2794 - root_mean_squared_error: 0.5286 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0269 - root_mean_squared_error: 0.1642 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0205 - root_mean_squared_error: 0.1432 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0188 - root_mean_squared_error: 0.1371 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0187 - root_mean_squared_error: 0.1366 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1364 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1152\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BD7068B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:38,809]\u001b[0m Trial 35 finished with value: 0.09857431846283883 and parameters: {'step': 2, 'no._units': 420}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0479 - root_mean_squared_error: 1.4311 - val_loss: 0.0371 - val_root_mean_squared_error: 0.1927\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2211 - root_mean_squared_error: 0.4702 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1478 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1076 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0992 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1663\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0969 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1646\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0093 - root_mean_squared_error: 0.0962 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1630\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0960 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1597\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1528\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1492\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1474\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1456\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1217\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1335\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1416\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1595\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1642\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1790\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029DF1D8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:41,975]\u001b[0m Trial 36 finished with value: 0.09286008661741159 and parameters: {'step': 2, 'no._units': 403}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4014 - root_mean_squared_error: 1.1838 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2051 - root_mean_squared_error: 0.4529 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1422 - root_mean_squared_error: 0.3771 - val_loss: 0.0386 - val_root_mean_squared_error: 0.1964\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1023 - root_mean_squared_error: 0.3198 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1969\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0840 - root_mean_squared_error: 0.2898 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0757 - root_mean_squared_error: 0.2752 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0719 - root_mean_squared_error: 0.2681 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1969\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - root_mean_squared_error: 0.2646 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1969\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - root_mean_squared_error: 0.2630 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - root_mean_squared_error: 0.2621 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - root_mean_squared_error: 0.2617 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1971\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - root_mean_squared_error: 0.2616 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - root_mean_squared_error: 0.2615 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1973\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1975\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1976\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1978\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1983\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1986\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1989\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1992\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1996\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2000\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2005\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2010\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2015\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2021\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0411 - val_root_mean_squared_error: 0.2027\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2034\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2050\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - root_mean_squared_error: 0.2614 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2058\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE9B3280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:43,463]\u001b[0m Trial 37 finished with value: 0.1960425010157573 and parameters: {'step': 3, 'no._units': 356}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1714 - root_mean_squared_error: 1.4736 - val_loss: 0.1090 - val_root_mean_squared_error: 0.3302\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3226 - root_mean_squared_error: 0.5680 - val_loss: 0.0705 - val_root_mean_squared_error: 0.2656\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0281 - root_mean_squared_error: 0.1676 - val_loss: 0.0578 - val_root_mean_squared_error: 0.2405\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0540 - val_root_mean_squared_error: 0.2324\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0141 - root_mean_squared_error: 0.1188 - val_loss: 0.0527 - val_root_mean_squared_error: 0.2297\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2289\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1097 - val_loss: 0.0525 - val_root_mean_squared_error: 0.2290\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1083 - val_loss: 0.0527 - val_root_mean_squared_error: 0.2295\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0530 - val_root_mean_squared_error: 0.2303\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1074 - val_loss: 0.0534 - val_root_mean_squared_error: 0.2311\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1072 - val_loss: 0.0538 - val_root_mean_squared_error: 0.2320\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2330\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2339\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0561 - val_root_mean_squared_error: 0.2369\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2379\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0571 - val_root_mean_squared_error: 0.2389\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2399\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2420\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2430\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2441\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2451\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2472\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2483\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0621 - val_root_mean_squared_error: 0.2493\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2503\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2514\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2524\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0642 - val_root_mean_squared_error: 0.2534\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0647 - val_root_mean_squared_error: 0.2544\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0653 - val_root_mean_squared_error: 0.2554\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2564\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - val_loss: 0.0663 - val_root_mean_squared_error: 0.2574\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A8A18B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:45,081]\u001b[0m Trial 38 finished with value: 0.228902423596705 and parameters: {'step': 3, 'no._units': 465}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4335 - root_mean_squared_error: 1.5600 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1548 - root_mean_squared_error: 0.3935 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - root_mean_squared_error: 0.2667 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0545 - root_mean_squared_error: 0.2333 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0493 - root_mean_squared_error: 0.2220 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1576\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0475 - root_mean_squared_error: 0.2180 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0469 - root_mean_squared_error: 0.2167 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0467 - root_mean_squared_error: 0.2162 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1594\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0467 - root_mean_squared_error: 0.2160 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1600\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2160 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1612\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1618\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1624\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1629\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1634\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1640\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1646\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1651\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1663\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1675\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1688\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1700\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1720\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1727\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029F8FD3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:46,528]\u001b[0m Trial 39 finished with value: 0.1454932334401527 and parameters: {'step': 2, 'no._units': 371}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9243 - root_mean_squared_error: 1.3872 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0830 - root_mean_squared_error: 0.2882 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0303 - root_mean_squared_error: 0.1741 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1592 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0238 - root_mean_squared_error: 0.1542 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - root_mean_squared_error: 0.1525 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1519 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1517 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B62EEC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:47,977]\u001b[0m Trial 40 finished with value: 0.09329033884628686 and parameters: {'step': 2, 'no._units': 437}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3454 - root_mean_squared_error: 1.5315 - val_loss: 0.0560 - val_root_mean_squared_error: 0.2366\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0175 - root_mean_squared_error: 1.0087 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1025 - root_mean_squared_error: 0.3202 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1594\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0549 - root_mean_squared_error: 0.2344 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0468 - root_mean_squared_error: 0.2163 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - root_mean_squared_error: 0.2112 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1597\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0439 - root_mean_squared_error: 0.2096 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1608\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0437 - root_mean_squared_error: 0.2090 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1620\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2089 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1644\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1697\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1712\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1772\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1788\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1804\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1853\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1871\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1889\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1907\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0371 - val_root_mean_squared_error: 0.1925\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1983\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2003\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2024\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4CE9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:49,527]\u001b[0m Trial 41 finished with value: 0.1583116313575732 and parameters: {'step': 2, 'no._units': 498}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1148 - root_mean_squared_error: 1.4542 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1804\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1711 - root_mean_squared_error: 0.4136 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1472\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0559 - root_mean_squared_error: 0.2365 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0469 - root_mean_squared_error: 0.2165 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0442 - root_mean_squared_error: 0.2102 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1345\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0433 - root_mean_squared_error: 0.2080 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0429 - root_mean_squared_error: 0.2072 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2069 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1362\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2069 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1369\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1376\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1446\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1474\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1525\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1604\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2068 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1616\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C6571790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:51,901]\u001b[0m Trial 42 finished with value: 0.13451302752752775 and parameters: {'step': 2, 'no._units': 450}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1819 - root_mean_squared_error: 1.4771 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1891\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0324 - root_mean_squared_error: 0.1801 - val_loss: 0.0471 - val_root_mean_squared_error: 0.2171\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0262 - root_mean_squared_error: 0.1620 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2230\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2235\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1329 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2232\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2228\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0168 - root_mean_squared_error: 0.1295 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2223\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - root_mean_squared_error: 0.1291 - val_loss: 0.0492 - val_root_mean_squared_error: 0.2218\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - root_mean_squared_error: 0.1290 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2212\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2207\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2202\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2196\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2190\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2184\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0471 - val_root_mean_squared_error: 0.2171\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2164\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0465 - val_root_mean_squared_error: 0.2156\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2149\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2141\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2133\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2125\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2116\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0444 - val_root_mean_squared_error: 0.2108\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2098\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2070\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2060\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2050\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1290 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE9B3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:53,344]\u001b[0m Trial 43 finished with value: 0.1891165073023216 and parameters: {'step': 2, 'no._units': 477}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4494 - root_mean_squared_error: 1.5651 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0586 - root_mean_squared_error: 0.2420 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - root_mean_squared_error: 0.1337 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1078 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1216\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0982 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - root_mean_squared_error: 0.0940 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0906 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1219\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1217\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1216\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1208\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1207\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1275\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1418\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1627\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE7AB160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:56,343]\u001b[0m Trial 44 finished with value: 0.10544270475761071 and parameters: {'step': 3, 'no._units': 417}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2270 - root_mean_squared_error: 1.4923 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6084 - root_mean_squared_error: 0.7800 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1237\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0855 - root_mean_squared_error: 0.2923 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0458 - root_mean_squared_error: 0.2141 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0354 - root_mean_squared_error: 0.1881 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0347 - root_mean_squared_error: 0.1862 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0344 - root_mean_squared_error: 0.1856 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1279\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1380\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029C6EB280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:58,014]\u001b[0m Trial 45 finished with value: 0.11236418786309922 and parameters: {'step': 2, 'no._units': 476}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.7043 - root_mean_squared_error: 1.6445 - val_loss: 0.0575 - val_root_mean_squared_error: 0.2398\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6372 - root_mean_squared_error: 0.7983 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0652 - root_mean_squared_error: 0.2554 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0356 - root_mean_squared_error: 0.1886 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1943\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0306 - root_mean_squared_error: 0.1750 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1945\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0293 - root_mean_squared_error: 0.1712 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1945\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1943\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1945\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1948\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1950\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1953\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1956\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1967\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1976\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1982\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1987\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1993\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020113D75F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 17:59:59,563]\u001b[0m Trial 46 finished with value: 0.19360544877207903 and parameters: {'step': 2, 'no._units': 500}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6690 - root_mean_squared_error: 1.2919 - val_loss: 0.0666 - val_root_mean_squared_error: 0.2581\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0834 - root_mean_squared_error: 0.2888 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1996\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0205 - root_mean_squared_error: 0.1432 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1892\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0145 - root_mean_squared_error: 0.1204 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1864\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0128 - root_mean_squared_error: 0.1132 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1858\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1108 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1859\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1100 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1862\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1097 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1865\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1870\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1874\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1884\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1889\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1895\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1901\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1908\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1914\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1921\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1943\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1951\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1959\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1968\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1976\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1985\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1994\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2003\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2013\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2022\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0413 - val_root_mean_squared_error: 0.2032\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2073\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A9EB3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:01,158]\u001b[0m Trial 47 finished with value: 0.1857755890671318 and parameters: {'step': 2, 'no._units': 407}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5993 - root_mean_squared_error: 1.2646 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1577 - root_mean_squared_error: 0.3972 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0362 - root_mean_squared_error: 0.1904 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - root_mean_squared_error: 0.1384 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1152\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - root_mean_squared_error: 0.1303 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1301 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A6F38820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:02,696]\u001b[0m Trial 48 finished with value: 0.11226820004535117 and parameters: {'step': 3, 'no._units': 443}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4407 - root_mean_squared_error: 1.2003 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1070 - root_mean_squared_error: 0.3271 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0198 - root_mean_squared_error: 0.1407 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0141 - root_mean_squared_error: 0.1187 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1134 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1118 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - root_mean_squared_error: 0.1113 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - root_mean_squared_error: 0.1111 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1302\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1323\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1332\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1337\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1343\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1353\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1359\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1362\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1110 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202ABB664C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:04,306]\u001b[0m Trial 49 finished with value: 0.12931777003872763 and parameters: {'step': 2, 'no._units': 376}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0096 - root_mean_squared_error: 1.0048 - val_loss: 0.1401 - val_root_mean_squared_error: 0.3744\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2326 - root_mean_squared_error: 0.4823 - val_loss: 0.0803 - val_root_mean_squared_error: 0.2833\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0686 - val_root_mean_squared_error: 0.2619\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0239 - root_mean_squared_error: 0.1547 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0181 - root_mean_squared_error: 0.1347 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2525\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0153 - root_mean_squared_error: 0.1239 - val_loss: 0.0634 - val_root_mean_squared_error: 0.2517\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0139 - root_mean_squared_error: 0.1180 - val_loss: 0.0633 - val_root_mean_squared_error: 0.2517\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - root_mean_squared_error: 0.1147 - val_loss: 0.0635 - val_root_mean_squared_error: 0.2519\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - root_mean_squared_error: 0.1129 - val_loss: 0.0636 - val_root_mean_squared_error: 0.2522\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1118 - val_loss: 0.0638 - val_root_mean_squared_error: 0.2527\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - root_mean_squared_error: 0.1112 - val_loss: 0.0641 - val_root_mean_squared_error: 0.2531\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1107 - val_loss: 0.0645 - val_root_mean_squared_error: 0.2540\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2545\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2554\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0654 - val_root_mean_squared_error: 0.2558\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0656 - val_root_mean_squared_error: 0.2562\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2565\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0660 - val_root_mean_squared_error: 0.2569\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0662 - val_root_mean_squared_error: 0.2573\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2576\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0665 - val_root_mean_squared_error: 0.2579\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2582\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0668 - val_root_mean_squared_error: 0.2585\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0670 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0671 - val_root_mean_squared_error: 0.2590\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0672 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0673 - val_root_mean_squared_error: 0.2594\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0673 - val_root_mean_squared_error: 0.2595\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2596\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0675 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0675 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2596\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B5DB0AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:05,966]\u001b[0m Trial 50 finished with value: 0.2516689962734852 and parameters: {'step': 4, 'no._units': 306}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4529 - root_mean_squared_error: 0.6730 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2461\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0934 - root_mean_squared_error: 0.3056 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0322 - root_mean_squared_error: 0.1794 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0140 - root_mean_squared_error: 0.1182 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0113 - root_mean_squared_error: 0.1065 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0100 - root_mean_squared_error: 0.1001 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1502\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1500\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0089 - root_mean_squared_error: 0.0946 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0086 - root_mean_squared_error: 0.0928 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0085 - root_mean_squared_error: 0.0924 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0922 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0921 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0919 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0919 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1500\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1502\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1508\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1514\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1516\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1520\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B1A5D4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:07,787]\u001b[0m Trial 51 finished with value: 0.14974287152125987 and parameters: {'step': 4, 'no._units': 180}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1888 - root_mean_squared_error: 1.4795 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0737 - root_mean_squared_error: 0.2715 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1243\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0179 - root_mean_squared_error: 0.1336 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1248\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - root_mean_squared_error: 0.1187 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - root_mean_squared_error: 0.1090 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1026 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - root_mean_squared_error: 0.0983 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - root_mean_squared_error: 0.0937 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - root_mean_squared_error: 0.0925 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1289\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0905 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1318\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1337\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1342\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1354\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1360\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AB90A040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:09,280]\u001b[0m Trial 52 finished with value: 0.12434327701191945 and parameters: {'step': 5, 'no._units': 464}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3846 - root_mean_squared_error: 0.6201 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - root_mean_squared_error: 0.2647 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1322\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0258 - root_mean_squared_error: 0.1607 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0229 - root_mean_squared_error: 0.1512 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0226 - root_mean_squared_error: 0.1504 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1501 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1370\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1360\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1345\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1327\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1321\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1275\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4CE9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:10,740]\u001b[0m Trial 53 finished with value: 0.12038442364830305 and parameters: {'step': 2, 'no._units': 141}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0469 - root_mean_squared_error: 1.0232 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2416\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0518 - root_mean_squared_error: 0.2276 - val_loss: 0.0776 - val_root_mean_squared_error: 0.2786\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - val_loss: 0.0785 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - root_mean_squared_error: 0.1151 - val_loss: 0.0782 - val_root_mean_squared_error: 0.2797\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1118 - val_loss: 0.0782 - val_root_mean_squared_error: 0.2796\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1108 - val_loss: 0.0782 - val_root_mean_squared_error: 0.2796\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0783 - val_root_mean_squared_error: 0.2798\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - val_loss: 0.0784 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0785 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0786 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0787 - val_root_mean_squared_error: 0.2805\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0788 - val_root_mean_squared_error: 0.2808\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0790 - val_root_mean_squared_error: 0.2810\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0791 - val_root_mean_squared_error: 0.2813\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0793 - val_root_mean_squared_error: 0.2816\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0795 - val_root_mean_squared_error: 0.2819\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0797 - val_root_mean_squared_error: 0.2822\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0799 - val_root_mean_squared_error: 0.2826\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0801 - val_root_mean_squared_error: 0.2830\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0803 - val_root_mean_squared_error: 0.2834\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0805 - val_root_mean_squared_error: 0.2838\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0808 - val_root_mean_squared_error: 0.2842\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0810 - val_root_mean_squared_error: 0.2846\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0813 - val_root_mean_squared_error: 0.2851\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0816 - val_root_mean_squared_error: 0.2856\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0818 - val_root_mean_squared_error: 0.2860\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0821 - val_root_mean_squared_error: 0.2865\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0824 - val_root_mean_squared_error: 0.2870\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0827 - val_root_mean_squared_error: 0.2876\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0830 - val_root_mean_squared_error: 0.2881\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0834 - val_root_mean_squared_error: 0.2887\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C7B35550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:12,188]\u001b[0m Trial 54 finished with value: 0.2415902937362445 and parameters: {'step': 2, 'no._units': 261}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3960 - root_mean_squared_error: 1.5479 - val_loss: 0.0638 - val_root_mean_squared_error: 0.2526\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2340 - root_mean_squared_error: 0.4837 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1955\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1009 - root_mean_squared_error: 0.3177 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1785\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0462 - root_mean_squared_error: 0.2149 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1745\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0300 - root_mean_squared_error: 0.1732 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0240 - root_mean_squared_error: 0.1550 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1715\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0214 - root_mean_squared_error: 0.1463 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0201 - root_mean_squared_error: 0.1417 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1392 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0190 - root_mean_squared_error: 0.1378 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1668\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0188 - root_mean_squared_error: 0.1370 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1655\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1643\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1630\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1361 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1617\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1360 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1604\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1360 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1565\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1524\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1469\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1427\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1413\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1385\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1343\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0865\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0741\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0721\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0704\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0704\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A75DADC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:20,474]\u001b[0m Trial 55 finished with value: 0.06969507730546112 and parameters: {'step': 4, 'no._units': 486}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.3872 - root_mean_squared_error: 1.5451 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3169 - root_mean_squared_error: 0.5630 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0221 - root_mean_squared_error: 0.1485 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0202 - root_mean_squared_error: 0.1421 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1387 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1369 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1360 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1353 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1351\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020292015430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:21,937]\u001b[0m Trial 56 finished with value: 0.10406907559457604 and parameters: {'step': 3, 'no._units': 485}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9299 - root_mean_squared_error: 1.3892 - val_loss: 0.1200 - val_root_mean_squared_error: 0.3464\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4345 - root_mean_squared_error: 0.6592 - val_loss: 0.1080 - val_root_mean_squared_error: 0.3286\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2158 - val_loss: 0.1151 - val_root_mean_squared_error: 0.3392\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1779 - val_loss: 0.1151 - val_root_mean_squared_error: 0.3393\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0250 - root_mean_squared_error: 0.1581 - val_loss: 0.1140 - val_root_mean_squared_error: 0.3376\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1476 - val_loss: 0.1128 - val_root_mean_squared_error: 0.3359\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0202 - root_mean_squared_error: 0.1421 - val_loss: 0.1120 - val_root_mean_squared_error: 0.3346\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1391 - val_loss: 0.1113 - val_root_mean_squared_error: 0.3336\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - root_mean_squared_error: 0.1374 - val_loss: 0.1108 - val_root_mean_squared_error: 0.3328\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.1103 - val_root_mean_squared_error: 0.3321\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.1099 - val_root_mean_squared_error: 0.3315\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1356 - val_loss: 0.1095 - val_root_mean_squared_error: 0.3309\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.1091 - val_root_mean_squared_error: 0.3303\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1353 - val_loss: 0.1087 - val_root_mean_squared_error: 0.3297\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.1083 - val_root_mean_squared_error: 0.3291\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.1079 - val_root_mean_squared_error: 0.3285\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.1075 - val_root_mean_squared_error: 0.3279\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.1071 - val_root_mean_squared_error: 0.3272\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.1066 - val_root_mean_squared_error: 0.3265\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1062 - val_root_mean_squared_error: 0.3259\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1057 - val_root_mean_squared_error: 0.3252\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1053 - val_root_mean_squared_error: 0.3244\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1048 - val_root_mean_squared_error: 0.3237\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1043 - val_root_mean_squared_error: 0.3229\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1038 - val_root_mean_squared_error: 0.3222\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1033 - val_root_mean_squared_error: 0.3214\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1028 - val_root_mean_squared_error: 0.3207\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1024 - val_root_mean_squared_error: 0.3199\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1018 - val_root_mean_squared_error: 0.3191\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1013 - val_root_mean_squared_error: 0.3183\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1008 - val_root_mean_squared_error: 0.3175\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.1002 - val_root_mean_squared_error: 0.3166\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0997 - val_root_mean_squared_error: 0.3158\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0992 - val_root_mean_squared_error: 0.3149\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0986 - val_root_mean_squared_error: 0.3140\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0980 - val_root_mean_squared_error: 0.3131\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0975 - val_root_mean_squared_error: 0.3122\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0969 - val_root_mean_squared_error: 0.3113\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0963 - val_root_mean_squared_error: 0.3103\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0957 - val_root_mean_squared_error: 0.3093\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0951 - val_root_mean_squared_error: 0.3084\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0945 - val_root_mean_squared_error: 0.3074\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0939 - val_root_mean_squared_error: 0.3064\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0933 - val_root_mean_squared_error: 0.3054\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0927 - val_root_mean_squared_error: 0.3044\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0920 - val_root_mean_squared_error: 0.3034\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0914 - val_root_mean_squared_error: 0.3024\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0908 - val_root_mean_squared_error: 0.3013\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0902 - val_root_mean_squared_error: 0.3003\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0895 - val_root_mean_squared_error: 0.2992\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0889 - val_root_mean_squared_error: 0.2982\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0883 - val_root_mean_squared_error: 0.2971\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0876 - val_root_mean_squared_error: 0.2960\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0870 - val_root_mean_squared_error: 0.2949\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0863 - val_root_mean_squared_error: 0.2938\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0857 - val_root_mean_squared_error: 0.2927\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0850 - val_root_mean_squared_error: 0.2916\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0844 - val_root_mean_squared_error: 0.2905\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0838 - val_root_mean_squared_error: 0.2894\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0831 - val_root_mean_squared_error: 0.2883\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0825 - val_root_mean_squared_error: 0.2872\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0818 - val_root_mean_squared_error: 0.2861\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2850\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0806 - val_root_mean_squared_error: 0.2839\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0800 - val_root_mean_squared_error: 0.2828\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0794 - val_root_mean_squared_error: 0.2817\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0788 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0782 - val_root_mean_squared_error: 0.2796\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0776 - val_root_mean_squared_error: 0.2785\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0770 - val_root_mean_squared_error: 0.2775\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0764 - val_root_mean_squared_error: 0.2764\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0758 - val_root_mean_squared_error: 0.2754\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0753 - val_root_mean_squared_error: 0.2744\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0747 - val_root_mean_squared_error: 0.2734\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0742 - val_root_mean_squared_error: 0.2724\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0737 - val_root_mean_squared_error: 0.2714\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0732 - val_root_mean_squared_error: 0.2705\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0727 - val_root_mean_squared_error: 0.2695\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0722 - val_root_mean_squared_error: 0.2687\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0717 - val_root_mean_squared_error: 0.2678\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0713 - val_root_mean_squared_error: 0.2669\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0708 - val_root_mean_squared_error: 0.2661\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0704 - val_root_mean_squared_error: 0.2654\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0700 - val_root_mean_squared_error: 0.2646\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0697 - val_root_mean_squared_error: 0.2639\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0693 - val_root_mean_squared_error: 0.2633\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0690 - val_root_mean_squared_error: 0.2626\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0687 - val_root_mean_squared_error: 0.2620\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0684 - val_root_mean_squared_error: 0.2615\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0681 - val_root_mean_squared_error: 0.2610\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0679 - val_root_mean_squared_error: 0.2605\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0677 - val_root_mean_squared_error: 0.2601\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0675 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0673 - val_root_mean_squared_error: 0.2594\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0671 - val_root_mean_squared_error: 0.2591\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0670 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0669 - val_root_mean_squared_error: 0.2586\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0668 - val_root_mean_squared_error: 0.2584\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2583\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2582\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0666 - val_root_mean_squared_error: 0.2581\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0666 - val_root_mean_squared_error: 0.2581\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0666 - val_root_mean_squared_error: 0.2581\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0666 - val_root_mean_squared_error: 0.2581\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2582\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2583\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0668 - val_root_mean_squared_error: 0.2584\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0669 - val_root_mean_squared_error: 0.2586\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0670 - val_root_mean_squared_error: 0.2588\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0671 - val_root_mean_squared_error: 0.2590\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0672 - val_root_mean_squared_error: 0.2592\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0673 - val_root_mean_squared_error: 0.2594\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2597\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0676 - val_root_mean_squared_error: 0.2599\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0677 - val_root_mean_squared_error: 0.2602\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0679 - val_root_mean_squared_error: 0.2605\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0680 - val_root_mean_squared_error: 0.2608\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0682 - val_root_mean_squared_error: 0.2611\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0684 - val_root_mean_squared_error: 0.2614\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0685 - val_root_mean_squared_error: 0.2618\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0687 - val_root_mean_squared_error: 0.2621\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0689 - val_root_mean_squared_error: 0.2624\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0691 - val_root_mean_squared_error: 0.2628\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0694 - val_root_mean_squared_error: 0.2635\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0696 - val_root_mean_squared_error: 0.2638\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0698 - val_root_mean_squared_error: 0.2641\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0699 - val_root_mean_squared_error: 0.2645\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0701 - val_root_mean_squared_error: 0.2648\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0703 - val_root_mean_squared_error: 0.2651\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0705 - val_root_mean_squared_error: 0.2655\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0706 - val_root_mean_squared_error: 0.2658\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A731C0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:26,593]\u001b[0m Trial 57 finished with value: 0.25810406377186534 and parameters: {'step': 4, 'no._units': 424}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2913 - root_mean_squared_error: 1.5137 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2099\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3141 - root_mean_squared_error: 0.5604 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1595\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0964 - root_mean_squared_error: 0.3106 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0619 - root_mean_squared_error: 0.2488 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1466\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0436 - root_mean_squared_error: 0.2089 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1450\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0349 - root_mean_squared_error: 0.1867 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - root_mean_squared_error: 0.1746 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0282 - root_mean_squared_error: 0.1679 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1460\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0269 - root_mean_squared_error: 0.1641 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0262 - root_mean_squared_error: 0.1619 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0258 - root_mean_squared_error: 0.1607 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0256 - root_mean_squared_error: 0.1600 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1595 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0254 - root_mean_squared_error: 0.1593 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1643\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1722\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1785\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1807\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1853\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1876\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1900\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1925\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1975\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2000\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C7A093A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:28,225]\u001b[0m Trial 58 finished with value: 0.1446952344752999 and parameters: {'step': 4, 'no._units': 450}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2583 - root_mean_squared_error: 1.8051 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1651\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2041 - root_mean_squared_error: 0.4517 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - root_mean_squared_error: 0.0974 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1675\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1673\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0744 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1674\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1679\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - root_mean_squared_error: 0.0690 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - root_mean_squared_error: 0.0685 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1686\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0682 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0680 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1693\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0679 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1697\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1700\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1711\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1715\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1718\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1722\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1725\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1731\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029DD3E1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:29,743]\u001b[0m Trial 59 finished with value: 0.16507821006004764 and parameters: {'step': 4, 'no._units': 500}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.0660 - root_mean_squared_error: 1.4373 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1386 - root_mean_squared_error: 0.3723 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0506 - root_mean_squared_error: 0.2250 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0323 - root_mean_squared_error: 0.1798 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0260 - root_mean_squared_error: 0.1614 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1451 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0200 - root_mean_squared_error: 0.1416 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - root_mean_squared_error: 0.1384 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1377 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - root_mean_squared_error: 0.1373 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - root_mean_squared_error: 0.1370 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1369 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1368 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1368 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - root_mean_squared_error: 0.1367 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C09811F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:31,253]\u001b[0m Trial 60 finished with value: 0.10054571386366917 and parameters: {'step': 4, 'no._units': 482}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2139 - root_mean_squared_error: 1.4879 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3380 - root_mean_squared_error: 0.5814 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0818 - root_mean_squared_error: 0.2860 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2139 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1672\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1782 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1725\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0260 - root_mean_squared_error: 0.1613 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1752\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - root_mean_squared_error: 0.1523 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - root_mean_squared_error: 0.1470 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1775\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - root_mean_squared_error: 0.1417 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1782\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1404 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1782\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1782\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0193 - root_mean_squared_error: 0.1390 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1386 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1384 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1777\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1776\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1775\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1380 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1773\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1380 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1772\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1380 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - root_mean_squared_error: 0.1380 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1770\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1380 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1768\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1763\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - root_mean_squared_error: 0.1379 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1761\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C060D5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:32,727]\u001b[0m Trial 61 finished with value: 0.1104303512040749 and parameters: {'step': 5, 'no._units': 464}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8961 - root_mean_squared_error: 1.7018 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1720 - root_mean_squared_error: 0.4148 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1476\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0538 - root_mean_squared_error: 0.2320 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0293 - root_mean_squared_error: 0.1713 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1393 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1353\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1338\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0126 - root_mean_squared_error: 0.1125 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1031 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0102 - root_mean_squared_error: 0.1009 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0994 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1289\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0097 - root_mean_squared_error: 0.0985 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0096 - root_mean_squared_error: 0.0979 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0095 - root_mean_squared_error: 0.0975 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0095 - root_mean_squared_error: 0.0972 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0971 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1243\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0970 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0969 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0969 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1214\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1327\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1358\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1390\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B46B24C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:36,055]\u001b[0m Trial 62 finished with value: 0.09065898802363787 and parameters: {'step': 5, 'no._units': 433}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1063 - root_mean_squared_error: 1.0518 - val_loss: 0.0724 - val_root_mean_squared_error: 0.2691\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4108 - root_mean_squared_error: 0.6409 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2338\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0944 - root_mean_squared_error: 0.3072 - val_loss: 0.0516 - val_root_mean_squared_error: 0.2272\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0323 - root_mean_squared_error: 0.1797 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2255\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2237\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0967 - val_loss: 0.0493 - val_root_mean_squared_error: 0.2221\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0068 - root_mean_squared_error: 0.0827 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2208\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0752 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2196\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0047 - root_mean_squared_error: 0.0684 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0045 - root_mean_squared_error: 0.0668 - val_loss: 0.0470 - val_root_mean_squared_error: 0.2169\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0043 - root_mean_squared_error: 0.0659 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2161\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0043 - root_mean_squared_error: 0.0652 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2153\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0042 - root_mean_squared_error: 0.0648 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2145\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0456 - val_root_mean_squared_error: 0.2137\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0644 - val_loss: 0.0453 - val_root_mean_squared_error: 0.2128\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0643 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2119\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0642 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2110\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0642 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2101\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2060\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2050\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0411 - val_root_mean_squared_error: 0.2028\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2018\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0403 - val_root_mean_squared_error: 0.2007\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1996\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1985\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1973\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1962\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1950\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0371 - val_root_mean_squared_error: 0.1926\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1914\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1901\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1889\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1876\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1863\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1851\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1825\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1813\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1800\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1787\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1775\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1722\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1696\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1656\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1643\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1630\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1617\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1604\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1521\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1479\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1452\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1419\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1410\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1398\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1398\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1409\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1413\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1427\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1444\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1479\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1516\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1524\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE4FA3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:40,381]\u001b[0m Trial 63 finished with value: 0.13972459188752318 and parameters: {'step': 5, 'no._units': 392}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4183 - root_mean_squared_error: 1.5551 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1982\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3644 - root_mean_squared_error: 0.6036 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1282 - root_mean_squared_error: 0.3580 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0985 - root_mean_squared_error: 0.3138 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0902 - root_mean_squared_error: 0.3003 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0875 - root_mean_squared_error: 0.2959 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0866 - root_mean_squared_error: 0.2944 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1581\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0863 - root_mean_squared_error: 0.2939 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2937 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1603\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1615\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1627\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1640\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1695\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1769\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1785\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1818\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1835\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1853\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1872\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1890\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1909\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1969\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1990\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0862 - root_mean_squared_error: 0.2936 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2011\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028DAD1310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:41,937]\u001b[0m Trial 64 finished with value: 0.15608675869745475 and parameters: {'step': 2, 'no._units': 490}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7862 - root_mean_squared_error: 0.8867 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1020 - root_mean_squared_error: 0.3194 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2338\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0346 - root_mean_squared_error: 0.1861 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2280\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0238 - root_mean_squared_error: 0.1541 - val_loss: 0.0505 - val_root_mean_squared_error: 0.2247\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0193 - root_mean_squared_error: 0.1389 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2228\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0492 - val_root_mean_squared_error: 0.2217\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0164 - root_mean_squared_error: 0.1282 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2210\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0160 - root_mean_squared_error: 0.1265 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2204\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0158 - root_mean_squared_error: 0.1257 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2199\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2195\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2190\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1250 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1250 - val_loss: 0.0476 - val_root_mean_squared_error: 0.2181\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1250 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2176\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2172\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0470 - val_root_mean_squared_error: 0.2167\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2162\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0465 - val_root_mean_squared_error: 0.2157\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0463 - val_root_mean_squared_error: 0.2151\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2146\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2141\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0456 - val_root_mean_squared_error: 0.2135\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0453 - val_root_mean_squared_error: 0.2129\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2122\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2115\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2109\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2102\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2087\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2079\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2063\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2055\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2046\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2038\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0411 - val_root_mean_squared_error: 0.2029\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2019\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2010\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2000\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1990\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1969\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1947\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1924\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1912\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1899\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1886\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1873\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1860\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1846\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1831\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1786\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1770\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1720\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1665\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1646\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1627\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1524\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1436\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1391\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1345\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1321\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0745\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0765\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028AE370D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:47,360]\u001b[0m Trial 65 finished with value: 0.07256769879234248 and parameters: {'step': 3, 'no._units': 202}. Best is trial 33 with value: 0.05357037665366858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4559 - root_mean_squared_error: 1.2066 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0580\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0999 - root_mean_squared_error: 0.3161 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - root_mean_squared_error: 0.2535 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0444 - root_mean_squared_error: 0.2108 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - root_mean_squared_error: 0.1892 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0301 - root_mean_squared_error: 0.1736 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0293 - root_mean_squared_error: 0.1712 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0686\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1690 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1690 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1690 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0598\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0584\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0571\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0558\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0531\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0518\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0504\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0489\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0475\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0460\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0444\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0429\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0413\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0398\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0333\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0317\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 9.0121e-04 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 8.0448e-04 - val_root_mean_squared_error: 0.0284\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 7.1359e-04 - val_root_mean_squared_error: 0.0267\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 6.2986e-04 - val_root_mean_squared_error: 0.0251\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 5.5334e-04 - val_root_mean_squared_error: 0.0235\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 4.8444e-04 - val_root_mean_squared_error: 0.0220\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 4.2368e-04 - val_root_mean_squared_error: 0.0206\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 3.7092e-04 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 3.2753e-04 - val_root_mean_squared_error: 0.0181\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 2.9412e-04 - val_root_mean_squared_error: 0.0172\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 2.7187e-04 - val_root_mean_squared_error: 0.0165\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 2.6085e-04 - val_root_mean_squared_error: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 2.6196e-04 - val_root_mean_squared_error: 0.0162\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 2.7656e-04 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 3.0539e-04 - val_root_mean_squared_error: 0.0175\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 3.4915e-04 - val_root_mean_squared_error: 0.0187\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 4.0865e-04 - val_root_mean_squared_error: 0.0202\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 4.8453e-04 - val_root_mean_squared_error: 0.0220\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 5.7720e-04 - val_root_mean_squared_error: 0.0240\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 6.8834e-04 - val_root_mean_squared_error: 0.0262\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 8.1890e-04 - val_root_mean_squared_error: 0.0286\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 9.6950e-04 - val_root_mean_squared_error: 0.0311\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0338\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0394\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0423\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0453\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0483\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0515\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0548\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0581\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B7435820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:50,168]\u001b[0m Trial 66 finished with value: 0.01615077453765188 and parameters: {'step': 3, 'no._units': 209}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.8323 - root_mean_squared_error: 0.9123 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - root_mean_squared_error: 0.2387 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2034\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1057 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2147\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - root_mean_squared_error: 0.0859 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2190\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0786 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2210\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - val_loss: 0.0493 - val_root_mean_squared_error: 0.2221\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0737 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2230\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2237\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - val_loss: 0.0504 - val_root_mean_squared_error: 0.2244\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2251\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0510 - val_root_mean_squared_error: 0.2258\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2265\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0516 - val_root_mean_squared_error: 0.2271\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0519 - val_root_mean_squared_error: 0.2278\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0522 - val_root_mean_squared_error: 0.2285\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0525 - val_root_mean_squared_error: 0.2291\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0528 - val_root_mean_squared_error: 0.2298\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0531 - val_root_mean_squared_error: 0.2304\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0534 - val_root_mean_squared_error: 0.2311\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2318\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0540 - val_root_mean_squared_error: 0.2324\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2331\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2338\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0550 - val_root_mean_squared_error: 0.2345\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0560 - val_root_mean_squared_error: 0.2366\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0563 - val_root_mean_squared_error: 0.2373\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0570 - val_root_mean_squared_error: 0.2387\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0573 - val_root_mean_squared_error: 0.2394\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C90FC430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:51,620]\u001b[0m Trial 67 finished with value: 0.17713770395004186 and parameters: {'step': 3, 'no._units': 273}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7865 - root_mean_squared_error: 0.8868 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1777\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1524 - root_mean_squared_error: 0.3904 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1615\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0240 - root_mean_squared_error: 0.1549 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0229 - root_mean_squared_error: 0.1512 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1519\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0193 - root_mean_squared_error: 0.1389 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1500\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1349 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0180 - root_mean_squared_error: 0.1342 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1495\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0179 - root_mean_squared_error: 0.1337 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0179 - root_mean_squared_error: 0.1336 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1488\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1336 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1336 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1336 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1336 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1475\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1468\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1453\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1444\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1440\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1429\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1424\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1418\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1391\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1384\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1358\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1338\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0592\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0579\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0568\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0561\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0556\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0555\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0558\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0565\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0589\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1313\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1384\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1419\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1453\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028AE37550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:56,677]\u001b[0m Trial 68 finished with value: 0.05553994754458807 and parameters: {'step': 3, 'no._units': 242}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5068 - root_mean_squared_error: 0.7119 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0846 - root_mean_squared_error: 0.2908 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0233 - root_mean_squared_error: 0.1526 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0190 - root_mean_squared_error: 0.1377 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1273 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - root_mean_squared_error: 0.1256 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - root_mean_squared_error: 0.1248 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1311\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - root_mean_squared_error: 0.1245 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1243 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1336\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1342\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1390\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1413\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1430\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1448\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1477\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1241 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020291B9D5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:58,271]\u001b[0m Trial 69 finished with value: 0.13006475852950394 and parameters: {'step': 3, 'no._units': 216}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7639 - root_mean_squared_error: 0.8740 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1832 - root_mean_squared_error: 0.4281 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1811\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - root_mean_squared_error: 0.1790 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1890\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0262 - root_mean_squared_error: 0.1618 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1892\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1544 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1895\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1511 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1898\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1495 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1901\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0221 - root_mean_squared_error: 0.1488 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1906\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - root_mean_squared_error: 0.1484 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1911\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - root_mean_squared_error: 0.1482 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1917\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1923\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1956\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1971\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1978\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1986\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1994\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2003\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2020\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2060\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2070\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4F474C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:00:59,735]\u001b[0m Trial 70 finished with value: 0.13066001320203957 and parameters: {'step': 3, 'no._units': 244}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6598 - root_mean_squared_error: 0.8123 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - root_mean_squared_error: 0.2389 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0340 - root_mean_squared_error: 0.1845 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0258 - root_mean_squared_error: 0.1606 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1508 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0215 - root_mean_squared_error: 0.1465 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1445 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1435 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0205 - root_mean_squared_error: 0.1431 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0204 - root_mean_squared_error: 0.1427 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0204 - root_mean_squared_error: 0.1427 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1341\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - root_mean_squared_error: 0.1426 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C7B35DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:02,153]\u001b[0m Trial 71 finished with value: 0.09011690691745422 and parameters: {'step': 3, 'no._units': 199}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6687 - root_mean_squared_error: 0.8177 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0249 - root_mean_squared_error: 0.1579 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - root_mean_squared_error: 0.1246 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - root_mean_squared_error: 0.0674 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - root_mean_squared_error: 0.0648 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - root_mean_squared_error: 0.0635 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - root_mean_squared_error: 0.0630 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0627 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0625 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0625 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0625 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - root_mean_squared_error: 0.0624 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029DF1D0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:05,843]\u001b[0m Trial 72 finished with value: 0.09082248678864596 and parameters: {'step': 3, 'no._units': 181}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8185 - root_mean_squared_error: 0.9047 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1106 - root_mean_squared_error: 0.3326 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - root_mean_squared_error: 0.2539 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0420 - root_mean_squared_error: 0.2048 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0345 - root_mean_squared_error: 0.1856 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0312 - root_mean_squared_error: 0.1767 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0290 - root_mean_squared_error: 0.1704 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1687 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1686 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0877\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0875\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020113D75F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:08,694]\u001b[0m Trial 73 finished with value: 0.0806373519500992 and parameters: {'step': 3, 'no._units': 235}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.9467 - root_mean_squared_error: 0.9730 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1352\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1140 - root_mean_squared_error: 0.3377 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1370\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - root_mean_squared_error: 0.2188 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - root_mean_squared_error: 0.1905 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0331 - root_mean_squared_error: 0.1820 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - root_mean_squared_error: 0.1793 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0318 - root_mean_squared_error: 0.1783 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1781 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1780 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1485\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1492\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1514\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1605\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1622\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028F049F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:10,255]\u001b[0m Trial 74 finished with value: 0.13523968961653537 and parameters: {'step': 2, 'no._units': 153}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6974 - root_mean_squared_error: 1.3029 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1139 - root_mean_squared_error: 0.3375 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0459 - root_mean_squared_error: 0.2143 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - root_mean_squared_error: 0.1559 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - root_mean_squared_error: 0.1303 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - root_mean_squared_error: 0.1183 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1391\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - root_mean_squared_error: 0.1121 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1069 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - root_mean_squared_error: 0.1053 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - root_mean_squared_error: 0.1047 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1046 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1436\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1442\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1444\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1446\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1448\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1450\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1452\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1454\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1456\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1460\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1462\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - root_mean_squared_error: 0.1044 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1468\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C060D310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:11,815]\u001b[0m Trial 75 finished with value: 0.12062832935840793 and parameters: {'step': 4, 'no._units': 293}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9969 - root_mean_squared_error: 0.9984 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - root_mean_squared_error: 0.2190 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2449\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0173 - root_mean_squared_error: 0.1315 - val_loss: 0.0633 - val_root_mean_squared_error: 0.2515\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - root_mean_squared_error: 0.1200 - val_loss: 0.0644 - val_root_mean_squared_error: 0.2537\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - root_mean_squared_error: 0.1149 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2545\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1129 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2547\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - root_mean_squared_error: 0.1123 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - root_mean_squared_error: 0.1120 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2549\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2549\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2551\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2551\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2552\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2552\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2552\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0651 - val_root_mean_squared_error: 0.2552\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2554\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2554\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0653 - val_root_mean_squared_error: 0.2555\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0653 - val_root_mean_squared_error: 0.2555\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0653 - val_root_mean_squared_error: 0.2554\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2554\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2554\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BA88DB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:13,285]\u001b[0m Trial 76 finished with value: 0.235786643139827 and parameters: {'step': 2, 'no._units': 315}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.7179 - root_mean_squared_error: 1.6486 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5494 - root_mean_squared_error: 0.7412 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0407 - root_mean_squared_error: 0.2019 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1301 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - root_mean_squared_error: 0.1174 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1130 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - root_mean_squared_error: 0.1098 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - root_mean_squared_error: 0.1093 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - root_mean_squared_error: 0.1091 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1275\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - root_mean_squared_error: 0.1089 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - root_mean_squared_error: 0.1089 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1089 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1290\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1305\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1313\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1322\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1336\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1345\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1360\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1370\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4CE9D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:14,790]\u001b[0m Trial 77 finished with value: 0.1126820402818668 and parameters: {'step': 3, 'no._units': 470}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0330 - root_mean_squared_error: 1.0164 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3851 - root_mean_squared_error: 0.6205 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1810 - root_mean_squared_error: 0.4254 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1937\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1356 - root_mean_squared_error: 0.3683 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1222 - root_mean_squared_error: 0.3496 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - root_mean_squared_error: 0.3433 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1164 - root_mean_squared_error: 0.3412 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1159 - root_mean_squared_error: 0.3405 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1158 - root_mean_squared_error: 0.3403 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1157 - root_mean_squared_error: 0.3402 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1932\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1157 - root_mean_squared_error: 0.3402 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1931\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1930\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1928\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1930\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1931\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1932\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1933\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1947\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1952\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1956\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1959\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1966\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1975\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1979\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1984\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1989\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0397 - val_root_mean_squared_error: 0.1994\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0400 - val_root_mean_squared_error: 0.1999\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2005\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1157 - root_mean_squared_error: 0.3401 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2017\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029C6EBF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:16,678]\u001b[0m Trial 78 finished with value: 0.1928488319861868 and parameters: {'step': 2, 'no._units': 193}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8323 - root_mean_squared_error: 0.9123 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0561 - root_mean_squared_error: 0.2369 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0295 - root_mean_squared_error: 0.1716 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0215 - root_mean_squared_error: 0.1466 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1735\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - root_mean_squared_error: 0.1305 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - root_mean_squared_error: 0.1218 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - root_mean_squared_error: 0.1171 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - root_mean_squared_error: 0.1144 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - root_mean_squared_error: 0.1128 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - root_mean_squared_error: 0.1119 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - root_mean_squared_error: 0.1114 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1790\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1800\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1108 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1810\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1107 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1821\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1107 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1833\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1107 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1844\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1856\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1868\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1880\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1892\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1905\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1931\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1945\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1986\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2000\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2015\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2029\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2044\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020295075C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:18,184]\u001b[0m Trial 79 finished with value: 0.1714011747132192 and parameters: {'step': 4, 'no._units': 253}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8646 - root_mean_squared_error: 1.3655 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3237 - root_mean_squared_error: 0.5690 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0392 - root_mean_squared_error: 0.1980 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1429\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0261 - root_mean_squared_error: 0.1615 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1409\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0204 - root_mean_squared_error: 0.1430 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0179 - root_mean_squared_error: 0.1338 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0167 - root_mean_squared_error: 0.1293 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0162 - root_mean_squared_error: 0.1272 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - root_mean_squared_error: 0.1256 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1254 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1407\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1411\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1424\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1429\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1442\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1452\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1469\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1476\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1482\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1521\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1251 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C972EA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:19,869]\u001b[0m Trial 80 finished with value: 0.13937991066718652 and parameters: {'step': 3, 'no._units': 462}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2086 - root_mean_squared_error: 1.0994 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1302\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0132 - root_mean_squared_error: 0.1151 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1107 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1087 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1072 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1323\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - root_mean_squared_error: 0.1070 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1069 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1069 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1366\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1385\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1473\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1525\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1595\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020283AED8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:22,341]\u001b[0m Trial 81 finished with value: 0.13004863428875776 and parameters: {'step': 3, 'no._units': 198}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8081 - root_mean_squared_error: 0.8989 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1652\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1008 - root_mean_squared_error: 0.3174 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - root_mean_squared_error: 0.2412 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1661\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0379 - root_mean_squared_error: 0.1946 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1618\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0298 - root_mean_squared_error: 0.1726 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0263 - root_mean_squared_error: 0.1623 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0248 - root_mean_squared_error: 0.1574 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0241 - root_mean_squared_error: 0.1551 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0237 - root_mean_squared_error: 0.1540 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0235 - root_mean_squared_error: 0.1534 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0235 - root_mean_squared_error: 0.1532 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1531 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1530 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1564\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1530 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1530 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1553\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1550\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1548\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1542\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1528\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1525\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1521\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1479\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1475\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1434\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1430\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1419\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1409\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1393\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1393\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1398\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1409\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1413\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1418\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1472\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1495\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1519\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - root_mean_squared_error: 0.1529 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C060D8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:26,694]\u001b[0m Trial 82 finished with value: 0.13933157265329751 and parameters: {'step': 3, 'no._units': 221}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5774 - root_mean_squared_error: 0.7599 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1782 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1321\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1141 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0914 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0070 - root_mean_squared_error: 0.0839 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1430\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - root_mean_squared_error: 0.0807 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0793 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0786 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1452\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1474\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1477\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1500\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1519\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AFEFF0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:28,149]\u001b[0m Trial 83 finished with value: 0.1294741512683368 and parameters: {'step': 3, 'no._units': 208}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3382 - root_mean_squared_error: 1.1568 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1232 - root_mean_squared_error: 0.3510 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0605 - root_mean_squared_error: 0.2460 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0353 - root_mean_squared_error: 0.1879 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0262 - root_mean_squared_error: 0.1618 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - root_mean_squared_error: 0.1425 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0200 - root_mean_squared_error: 0.1413 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1407 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1405 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0865\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0745\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0745\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B4AF1940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:32,343]\u001b[0m Trial 84 finished with value: 0.07369138136611983 and parameters: {'step': 3, 'no._units': 161}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4163 - root_mean_squared_error: 0.6452 - val_loss: 0.0803 - val_root_mean_squared_error: 0.2833\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0400 - root_mean_squared_error: 0.2001 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1893\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1536 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1745\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1399 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1334 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1720\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1332 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1753\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1790\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1800\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1810\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1851\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1862\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1874\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1885\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1897\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1909\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1922\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1935\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1962\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1976\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1990\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2005\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2019\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2034\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BF284A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:33,956]\u001b[0m Trial 85 finished with value: 0.17088184026281117 and parameters: {'step': 2, 'no._units': 170}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7300 - root_mean_squared_error: 0.8544 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0640 - root_mean_squared_error: 0.2531 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0266 - root_mean_squared_error: 0.1631 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0201 - root_mean_squared_error: 0.1416 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1334 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0168 - root_mean_squared_error: 0.1297 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - root_mean_squared_error: 0.1279 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0161 - root_mean_squared_error: 0.1270 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - root_mean_squared_error: 0.1265 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - root_mean_squared_error: 0.1263 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1262 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1262 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - root_mean_squared_error: 0.1262 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202903FDC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:35,495]\u001b[0m Trial 86 finished with value: 0.09358163112453405 and parameters: {'step': 3, 'no._units': 236}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6972 - root_mean_squared_error: 1.3028 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1338\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3946 - root_mean_squared_error: 0.6281 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1135 - root_mean_squared_error: 0.3369 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0745 - root_mean_squared_error: 0.2730 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0640 - root_mean_squared_error: 0.2531 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0608 - root_mean_squared_error: 0.2465 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0597 - root_mean_squared_error: 0.2443 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0593 - root_mean_squared_error: 0.2436 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0592 - root_mean_squared_error: 0.2433 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0592 - root_mean_squared_error: 0.2433 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - root_mean_squared_error: 0.2432 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BA88D670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:37,253]\u001b[0m Trial 87 finished with value: 0.09200486109529465 and parameters: {'step': 2, 'no._units': 447}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6572 - root_mean_squared_error: 0.8107 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0655 - root_mean_squared_error: 0.2560 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0354 - root_mean_squared_error: 0.1881 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0222 - root_mean_squared_error: 0.1490 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - root_mean_squared_error: 0.1218 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - root_mean_squared_error: 0.1178 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - root_mean_squared_error: 0.1158 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - root_mean_squared_error: 0.1149 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - root_mean_squared_error: 0.1144 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1142 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - root_mean_squared_error: 0.1141 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1207\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1141 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1141 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1219\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1231\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BA5940D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:38,750]\u001b[0m Trial 88 finished with value: 0.11166593340090886 and parameters: {'step': 3, 'no._units': 190}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.9918 - root_mean_squared_error: 0.9959 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2233\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1355 - root_mean_squared_error: 0.3680 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1845\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0766 - root_mean_squared_error: 0.2767 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1748\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0603 - root_mean_squared_error: 0.2456 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0551 - root_mean_squared_error: 0.2348 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1731\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0534 - root_mean_squared_error: 0.2311 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0528 - root_mean_squared_error: 0.2298 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0526 - root_mean_squared_error: 0.2294 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1768\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0526 - root_mean_squared_error: 0.2292 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1798\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1813\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1844\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1861\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1877\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1894\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1912\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1930\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1948\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0386 - val_root_mean_squared_error: 0.1966\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1984\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2003\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2023\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2102\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2122\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2143\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2164\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2208\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2230\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2253\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028D848670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:40,318]\u001b[0m Trial 89 finished with value: 0.17276326613922754 and parameters: {'step': 2, 'no._units': 225}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1074 - root_mean_squared_error: 1.4517 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4176 - root_mean_squared_error: 0.6462 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0461 - root_mean_squared_error: 0.2148 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0251 - root_mean_squared_error: 0.1585 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1454 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - root_mean_squared_error: 0.1416 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - root_mean_squared_error: 0.1404 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1399 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0694\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0665\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0677\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0683\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0696\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BD395CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:42,500]\u001b[0m Trial 90 finished with value: 0.06549971298822092 and parameters: {'step': 2, 'no._units': 410}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4473 - root_mean_squared_error: 1.5644 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2022 - root_mean_squared_error: 0.4497 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0699 - root_mean_squared_error: 0.2643 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0465 - root_mean_squared_error: 0.2158 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0398 - root_mean_squared_error: 0.1995 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0369 - root_mean_squared_error: 0.1920 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0366 - root_mean_squared_error: 0.1914 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1912 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0365 - root_mean_squared_error: 0.1911 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4F474C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:44,616]\u001b[0m Trial 91 finished with value: 0.06371879815237207 and parameters: {'step': 2, 'no._units': 410}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7668 - root_mean_squared_error: 1.3292 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1907\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1505 - root_mean_squared_error: 0.3879 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0999 - root_mean_squared_error: 0.3161 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1475\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0811 - root_mean_squared_error: 0.2848 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1466\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0742 - root_mean_squared_error: 0.2724 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0717 - root_mean_squared_error: 0.2678 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1479\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0708 - root_mean_squared_error: 0.2662 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1488\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - root_mean_squared_error: 0.2656 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2654 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2654 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1600\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1612\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1637\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1663\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1677\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1720\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1797\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1814\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202998B1550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:46,162]\u001b[0m Trial 92 finished with value: 0.14663918797948663 and parameters: {'step': 2, 'no._units': 407}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8226 - root_mean_squared_error: 1.3500 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2202\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5501 - root_mean_squared_error: 0.7417 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1656\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1689 - root_mean_squared_error: 0.4110 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1283 - root_mean_squared_error: 0.3582 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1176 - root_mean_squared_error: 0.3429 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1582\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1142 - root_mean_squared_error: 0.3379 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1130 - root_mean_squared_error: 0.3362 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1127 - root_mean_squared_error: 0.3357 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1604\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1125 - root_mean_squared_error: 0.3355 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1612\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1620\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1628\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1636\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1645\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1661\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1678\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1687\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1695\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1774\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1785\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1796\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1844\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1125 - root_mean_squared_error: 0.3354 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CAD8C4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:47,734]\u001b[0m Trial 93 finished with value: 0.15800772182370937 and parameters: {'step': 2, 'no._units': 385}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6280 - root_mean_squared_error: 1.2759 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1153 - root_mean_squared_error: 0.3395 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1255 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1380\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1088 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1385\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - root_mean_squared_error: 0.1070 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1388\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1392\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1061 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1403\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1407\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1410\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1418\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1421\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1429\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1444\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1453\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1469\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1473\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1477\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1482\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - root_mean_squared_error: 0.1059 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B46B2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:50,050]\u001b[0m Trial 94 finished with value: 0.1371577367665887 and parameters: {'step': 2, 'no._units': 426}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1658 - root_mean_squared_error: 1.0797 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1859\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0645 - root_mean_squared_error: 0.2539 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0348 - root_mean_squared_error: 0.1867 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1427\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0284 - root_mean_squared_error: 0.1686 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0265 - root_mean_squared_error: 0.1627 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1366\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0258 - root_mean_squared_error: 0.1606 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1358\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0256 - root_mean_squared_error: 0.1600 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1353\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1343\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1336\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1332\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1324\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1303\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1290\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1282\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1237\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1208\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1214\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1270\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1321\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1336\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1352\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1369\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1446\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - root_mean_squared_error: 0.1596 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AB52CB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:53,262]\u001b[0m Trial 95 finished with value: 0.11916491006701056 and parameters: {'step': 2, 'no._units': 366}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5175 - root_mean_squared_error: 1.2319 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1627 - root_mean_squared_error: 0.4033 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0816 - root_mean_squared_error: 0.2856 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0609 - root_mean_squared_error: 0.2469 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0544 - root_mean_squared_error: 0.2333 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0522 - root_mean_squared_error: 0.2285 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0515 - root_mean_squared_error: 0.2268 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0512 - root_mean_squared_error: 0.2263 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - root_mean_squared_error: 0.2261 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1453\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1609\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B4AF1550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:56,628]\u001b[0m Trial 96 finished with value: 0.10008809930988283 and parameters: {'step': 2, 'no._units': 404}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.0215 - root_mean_squared_error: 1.4218 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1328 - root_mean_squared_error: 0.3645 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0566 - root_mean_squared_error: 0.2379 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0417 - root_mean_squared_error: 0.2042 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0373 - root_mean_squared_error: 0.1930 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0358 - root_mean_squared_error: 0.1892 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0353 - root_mean_squared_error: 0.1879 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - root_mean_squared_error: 0.1873 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B74350D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:01:59,039]\u001b[0m Trial 97 finished with value: 0.09233526832986244 and parameters: {'step': 2, 'no._units': 432}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3327 - root_mean_squared_error: 1.1544 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0859 - root_mean_squared_error: 0.2931 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0293 - root_mean_squared_error: 0.1713 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - root_mean_squared_error: 0.1530 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - root_mean_squared_error: 0.1469 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0210 - root_mean_squared_error: 0.1448 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - root_mean_squared_error: 0.1441 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1439 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0765\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0704\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0572\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0552\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0532\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0511\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0490\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0468\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0446\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0424\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0332\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 9.6131e-04 - val_root_mean_squared_error: 0.0310\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 8.3217e-04 - val_root_mean_squared_error: 0.0288\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 7.1832e-04 - val_root_mean_squared_error: 0.0268\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 6.2089e-04 - val_root_mean_squared_error: 0.0249\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 5.4154e-04 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 4.8041e-04 - val_root_mean_squared_error: 0.0219\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 4.3833e-04 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 4.1587e-04 - val_root_mean_squared_error: 0.0204\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 4.1393e-04 - val_root_mean_squared_error: 0.0203\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 4.3311e-04 - val_root_mean_squared_error: 0.0208\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 4.7367e-04 - val_root_mean_squared_error: 0.0218\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 5.3587e-04 - val_root_mean_squared_error: 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 6.1977e-04 - val_root_mean_squared_error: 0.0249\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 7.2551e-04 - val_root_mean_squared_error: 0.0269\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 8.5302e-04 - val_root_mean_squared_error: 0.0292\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0317\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0425\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0454\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0482\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0511\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0540\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0568\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0858\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C77DACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:03,451]\u001b[0m Trial 98 finished with value: 0.02034521753608027 and parameters: {'step': 2, 'no._units': 345}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.6662 - root_mean_squared_error: 1.6328 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1769 - root_mean_squared_error: 0.4206 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0563 - root_mean_squared_error: 0.2372 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1984 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1877 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0340 - root_mean_squared_error: 0.1845 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BD3950D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:04,964]\u001b[0m Trial 99 finished with value: 0.0843721758367874 and parameters: {'step': 2, 'no._units': 412}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4524 - root_mean_squared_error: 1.2051 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - root_mean_squared_error: 0.2581 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - root_mean_squared_error: 0.1471 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - root_mean_squared_error: 0.1371 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1361 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1357 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C1D73940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:06,433]\u001b[0m Trial 100 finished with value: 0.0806704881679229 and parameters: {'step': 2, 'no._units': 335}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4515 - root_mean_squared_error: 1.2048 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2033 - root_mean_squared_error: 0.4509 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1392\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0291 - root_mean_squared_error: 0.1707 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1430\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1233 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - root_mean_squared_error: 0.1114 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1461\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1080 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1469\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1069 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1477\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1065 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1064 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1581\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1594\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1614\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1622\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1629\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1636\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1643\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B7759820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:07,943]\u001b[0m Trial 101 finished with value: 0.13916268852788194 and parameters: {'step': 2, 'no._units': 342}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1969 - root_mean_squared_error: 1.4822 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1821\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2966 - root_mean_squared_error: 0.5446 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0323 - root_mean_squared_error: 0.1797 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0238 - root_mean_squared_error: 0.1541 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1707\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0220 - root_mean_squared_error: 0.1484 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0215 - root_mean_squared_error: 0.1465 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0213 - root_mean_squared_error: 0.1459 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1457 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1456 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1760\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - root_mean_squared_error: 0.1456 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - root_mean_squared_error: 0.1456 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1772\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1778\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1784\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1790\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1796\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1807\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1813\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1818\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1824\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1829\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1840\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1845\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1851\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1862\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1867\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1872\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1877\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1882\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1887\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029809EDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:09,437]\u001b[0m Trial 102 finished with value: 0.15742196576286116 and parameters: {'step': 2, 'no._units': 455}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3769 - root_mean_squared_error: 1.5417 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6218 - root_mean_squared_error: 0.7885 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0514 - root_mean_squared_error: 0.2268 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0222 - root_mean_squared_error: 0.1489 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - root_mean_squared_error: 0.1442 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1284\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - root_mean_squared_error: 0.1437 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1322\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1327\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1353\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1369\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1386\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1450\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1476\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - root_mean_squared_error: 0.1437 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1505\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202982D0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:11,028]\u001b[0m Trial 103 finished with value: 0.1279750759995913 and parameters: {'step': 2, 'no._units': 441}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4479 - root_mean_squared_error: 1.5646 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5339 - root_mean_squared_error: 0.7307 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0802 - root_mean_squared_error: 0.2832 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0406 - root_mean_squared_error: 0.2014 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - root_mean_squared_error: 0.1965 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0380 - root_mean_squared_error: 0.1950 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1943 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1207\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1323\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1390\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1427\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B3377B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:13,369]\u001b[0m Trial 104 finished with value: 0.09868167328294282 and parameters: {'step': 2, 'no._units': 491}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3174 - root_mean_squared_error: 1.1478 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1658\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0976 - root_mean_squared_error: 0.3124 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0274 - root_mean_squared_error: 0.1656 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1481 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0199 - root_mean_squared_error: 0.1410 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1342\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1336\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1319\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1279\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1243\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1303\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1454\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1492\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C30B0310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:17,129]\u001b[0m Trial 105 finished with value: 0.08590727913112294 and parameters: {'step': 2, 'no._units': 394}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.3813 - root_mean_squared_error: 1.5431 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3562 - root_mean_squared_error: 0.5968 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0666 - root_mean_squared_error: 0.2581 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0479 - root_mean_squared_error: 0.2188 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0435 - root_mean_squared_error: 0.2085 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0421 - root_mean_squared_error: 0.2053 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1565\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0417 - root_mean_squared_error: 0.2042 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2038 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2037 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1611\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1620\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1630\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1639\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1649\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1660\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1681\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1693\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1717\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1730\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1769\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1797\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1812\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1826\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1855\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1870\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1885\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC4E11F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:18,660]\u001b[0m Trial 106 finished with value: 0.1534477082634496 and parameters: {'step': 2, 'no._units': 474}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5695 - root_mean_squared_error: 1.2528 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2063\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6159 - root_mean_squared_error: 0.7848 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1678 - root_mean_squared_error: 0.4097 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1652\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1205 - root_mean_squared_error: 0.3471 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1645\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1088 - root_mean_squared_error: 0.3299 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1652\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1053 - root_mean_squared_error: 0.3245 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1664\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1041 - root_mean_squared_error: 0.3227 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1677\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1037 - root_mean_squared_error: 0.3221 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1036 - root_mean_squared_error: 0.3219 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1036 - root_mean_squared_error: 0.3218 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1719\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1797\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1814\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1831\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1848\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1866\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1884\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1922\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2000\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2020\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2041\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2104\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2149\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1035 - root_mean_squared_error: 0.3218 - val_loss: 0.0471 - val_root_mean_squared_error: 0.2171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CDAAA8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:20,221]\u001b[0m Trial 107 finished with value: 0.16453504345855455 and parameters: {'step': 2, 'no._units': 384}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4705 - root_mean_squared_error: 1.2126 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0957 - root_mean_squared_error: 0.3094 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0188 - root_mean_squared_error: 0.1371 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0141 - root_mean_squared_error: 0.1185 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0122 - root_mean_squared_error: 0.1106 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0121 - root_mean_squared_error: 0.1099 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0858\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029B25AC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:23,540]\u001b[0m Trial 108 finished with value: 0.07974640564196024 and parameters: {'step': 2, 'no._units': 361}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3967 - root_mean_squared_error: 1.1818 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3178 - root_mean_squared_error: 0.5637 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1243\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0499 - root_mean_squared_error: 0.2233 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0439 - root_mean_squared_error: 0.2095 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0414 - root_mean_squared_error: 0.2034 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2010 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0401 - root_mean_squared_error: 0.2002 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0400 - root_mean_squared_error: 0.1999 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1324\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1354\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1364\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1374\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1385\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1444\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1469\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202837BBEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:25,122]\u001b[0m Trial 109 finished with value: 0.1226417410906367 and parameters: {'step': 2, 'no._units': 418}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1531 - root_mean_squared_error: 1.4673 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1502\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2726 - root_mean_squared_error: 0.5221 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1462\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0320 - root_mean_squared_error: 0.1789 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1633\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0221 - root_mean_squared_error: 0.1488 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - root_mean_squared_error: 0.1237 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0142 - root_mean_squared_error: 0.1193 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - root_mean_squared_error: 0.1169 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - root_mean_squared_error: 0.1156 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - root_mean_squared_error: 0.1148 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - root_mean_squared_error: 0.1143 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1674\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1139 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1656\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1138 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1637\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1618\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1599\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1337\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1335\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1429\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1645\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1684\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1723\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1763\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020113D39F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:27,998]\u001b[0m Trial 110 finished with value: 0.10524485835323255 and parameters: {'step': 4, 'no._units': 481}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7447 - root_mean_squared_error: 1.3209 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1718\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2278 - root_mean_squared_error: 0.4773 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0294 - root_mean_squared_error: 0.1715 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - root_mean_squared_error: 0.1417 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2077\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2075\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2078\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0153 - root_mean_squared_error: 0.1237 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2097\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1234 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1233 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2122\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0454 - val_root_mean_squared_error: 0.2131\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2140\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2149\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2158\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0470 - val_root_mean_squared_error: 0.2167\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2176\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2185\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0481 - val_root_mean_squared_error: 0.2193\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2202\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0489 - val_root_mean_squared_error: 0.2211\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0492 - val_root_mean_squared_error: 0.2219\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2228\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0500 - val_root_mean_squared_error: 0.2237\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0504 - val_root_mean_squared_error: 0.2246\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2255\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0512 - val_root_mean_squared_error: 0.2264\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0516 - val_root_mean_squared_error: 0.2273\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0521 - val_root_mean_squared_error: 0.2282\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0525 - val_root_mean_squared_error: 0.2291\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020299A5B3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:29,501]\u001b[0m Trial 111 finished with value: 0.17179560496792212 and parameters: {'step': 3, 'no._units': 457}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.9200 - root_mean_squared_error: 0.9592 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0507 - root_mean_squared_error: 0.2251 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0260 - root_mean_squared_error: 0.1614 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - root_mean_squared_error: 0.1445 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0193 - root_mean_squared_error: 0.1388 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - root_mean_squared_error: 0.1368 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - root_mean_squared_error: 0.1362 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1152\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029DF1D9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:31,074]\u001b[0m Trial 112 finished with value: 0.1059901153960115 and parameters: {'step': 2, 'no._units': 272}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6222 - root_mean_squared_error: 0.7888 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0278 - root_mean_squared_error: 0.1666 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - root_mean_squared_error: 0.1160 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0103 - root_mean_squared_error: 0.1016 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1342\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0086 - root_mean_squared_error: 0.0928 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1311\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - root_mean_squared_error: 0.0908 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0905 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1305\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1303\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1302\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1290\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1282\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1270\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1345\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1392\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0903 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1451\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BF284790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:34,126]\u001b[0m Trial 113 finished with value: 0.12498130933264187 and parameters: {'step': 3, 'no._units': 208}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.0760 - root_mean_squared_error: 1.4408 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1059 - root_mean_squared_error: 0.3254 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0662 - root_mean_squared_error: 0.2573 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0437 - root_mean_squared_error: 0.2091 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0301 - root_mean_squared_error: 0.1736 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0283 - root_mean_squared_error: 0.1682 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0274 - root_mean_squared_error: 0.1655 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1642 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0268 - root_mean_squared_error: 0.1636 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0267 - root_mean_squared_error: 0.1633 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1632 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1514\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1631 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1520\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1631 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1550\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1599\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1612\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1618\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1631\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1638\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1644\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1651\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202995FAAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:35,799]\u001b[0m Trial 114 finished with value: 0.14855404084063956 and parameters: {'step': 3, 'no._units': 469}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5783 - root_mean_squared_error: 1.2563 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1479\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1676 - root_mean_squared_error: 0.4094 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2012\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0388 - root_mean_squared_error: 0.1970 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2223\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0326 - root_mean_squared_error: 0.1806 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2231\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - root_mean_squared_error: 0.1788 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2226\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - root_mean_squared_error: 0.1782 - val_loss: 0.0492 - val_root_mean_squared_error: 0.2218\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2207\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - root_mean_squared_error: 0.1779 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2196\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2185\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2174\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2162\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2150\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2139\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2127\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2115\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2102\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2078\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2065\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0411 - val_root_mean_squared_error: 0.2027\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2014\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2001\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1988\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1975\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1962\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1949\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1923\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C1FCCA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:37,288]\u001b[0m Trial 115 finished with value: 0.14786803268879645 and parameters: {'step': 2, 'no._units': 399}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2177 - root_mean_squared_error: 1.4892 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - root_mean_squared_error: 0.4963 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0251 - root_mean_squared_error: 0.1584 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - root_mean_squared_error: 0.1208 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - root_mean_squared_error: 0.1120 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1094 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.1085 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A6F389D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:38,757]\u001b[0m Trial 116 finished with value: 0.08689200240011713 and parameters: {'step': 2, 'no._units': 498}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1654 - root_mean_squared_error: 1.4715 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2290\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3353 - root_mean_squared_error: 0.5790 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1015 - root_mean_squared_error: 0.3186 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0734 - root_mean_squared_error: 0.2710 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0587 - root_mean_squared_error: 0.2423 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0519 - root_mean_squared_error: 0.2278 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0487 - root_mean_squared_error: 0.2207 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0472 - root_mean_squared_error: 0.2173 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0465 - root_mean_squared_error: 0.2156 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0461 - root_mean_squared_error: 0.2148 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0460 - root_mean_squared_error: 0.2144 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0459 - root_mean_squared_error: 0.2142 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - root_mean_squared_error: 0.2141 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2141 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A5C755E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:40,326]\u001b[0m Trial 117 finished with value: 0.10128985697482962 and parameters: {'step': 3, 'no._units': 485}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2896 - root_mean_squared_error: 1.5131 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2055\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5613 - root_mean_squared_error: 0.7492 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1873\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - root_mean_squared_error: 0.2653 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1905\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2178 - val_loss: 0.0367 - val_root_mean_squared_error: 0.1916\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0396 - root_mean_squared_error: 0.1990 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - root_mean_squared_error: 0.1893 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0331 - root_mean_squared_error: 0.1819 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0326 - root_mean_squared_error: 0.1807 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0324 - root_mean_squared_error: 0.1801 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0323 - root_mean_squared_error: 0.1798 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0323 - root_mean_squared_error: 0.1796 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1919\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1920\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1921\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1922\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1923\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1925\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0371 - val_root_mean_squared_error: 0.1926\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1928\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1930\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1932\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0378 - val_root_mean_squared_error: 0.1944\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1946\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1948\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0380 - val_root_mean_squared_error: 0.1950\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1952\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1955\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B62EE0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:41,820]\u001b[0m Trial 118 finished with value: 0.18731922101035123 and parameters: {'step': 3, 'no._units': 426}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8909 - root_mean_squared_error: 1.3751 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1384\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1805 - root_mean_squared_error: 0.4249 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0200 - root_mean_squared_error: 0.1413 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0101 - root_mean_squared_error: 0.1005 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0088 - root_mean_squared_error: 0.0935 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0080 - root_mean_squared_error: 0.0896 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0073 - root_mean_squared_error: 0.0853 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0072 - root_mean_squared_error: 0.0849 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0072 - root_mean_squared_error: 0.0846 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0844 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4F47AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:44,378]\u001b[0m Trial 119 finished with value: 0.10062308687165979 and parameters: {'step': 4, 'no._units': 437}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5634 - root_mean_squared_error: 1.2504 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2827 - root_mean_squared_error: 0.5317 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1047 - root_mean_squared_error: 0.3235 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0744 - root_mean_squared_error: 0.2727 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0657 - root_mean_squared_error: 0.2564 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0629 - root_mean_squared_error: 0.2509 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0620 - root_mean_squared_error: 0.2490 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - root_mean_squared_error: 0.2484 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0616 - root_mean_squared_error: 0.2482 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC2D5C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:45,822]\u001b[0m Trial 120 finished with value: 0.06794692867275465 and parameters: {'step': 2, 'no._units': 411}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4851 - root_mean_squared_error: 1.2187 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0953 - root_mean_squared_error: 0.3087 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - root_mean_squared_error: 0.1341 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1219 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1158\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - root_mean_squared_error: 0.1166 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0131 - root_mean_squared_error: 0.1147 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1139 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1137 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1209\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1214\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1270\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1324\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1332\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1341\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC6B4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:48,197]\u001b[0m Trial 121 finished with value: 0.11167804790827852 and parameters: {'step': 2, 'no._units': 413}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.8151 - root_mean_squared_error: 1.3473 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1362 - root_mean_squared_error: 0.3691 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1345\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0464 - root_mean_squared_error: 0.2153 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0329 - root_mean_squared_error: 0.1815 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0293 - root_mean_squared_error: 0.1713 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0282 - root_mean_squared_error: 0.1680 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0278 - root_mean_squared_error: 0.1669 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1269\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1302\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1305\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1318\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1322\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0277 - root_mean_squared_error: 0.1663 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A75DAB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:49,897]\u001b[0m Trial 122 finished with value: 0.1258974163965697 and parameters: {'step': 2, 'no._units': 423}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4583 - root_mean_squared_error: 1.2076 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0595 - root_mean_squared_error: 0.2439 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1603 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0238 - root_mean_squared_error: 0.1542 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1521 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1511 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020283EDB430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:51,373]\u001b[0m Trial 123 finished with value: 0.08923292384606514 and parameters: {'step': 2, 'no._units': 379}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5642 - root_mean_squared_error: 0.7511 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1029 - root_mean_squared_error: 0.3207 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0372 - root_mean_squared_error: 0.1930 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0276 - root_mean_squared_error: 0.1662 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0249 - root_mean_squared_error: 0.1578 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0240 - root_mean_squared_error: 0.1549 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0237 - root_mean_squared_error: 0.1540 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1536 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0696\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0682\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0669\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0665\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0644\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0669\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0677\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0693\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - root_mean_squared_error: 0.1535 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BBE3C670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:53,918]\u001b[0m Trial 124 finished with value: 0.0638446478240437 and parameters: {'step': 2, 'no._units': 227}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.7893 - root_mean_squared_error: 0.8884 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - root_mean_squared_error: 0.1490 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0204 - root_mean_squared_error: 0.1430 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0199 - root_mean_squared_error: 0.1410 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0695\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0683\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0671\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0584\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0572\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0559\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0547\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0535\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0524\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0513\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0502\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0481\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0464\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0456\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0449\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0442\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0437\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0433\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0430\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0428\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0427\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0427\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0429\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0436\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0442\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0449\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0457\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0490\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0503\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0533\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0549\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0567\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0585\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0605\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC4E13A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:57,121]\u001b[0m Trial 125 finished with value: 0.04266826740010064 and parameters: {'step': 2, 'no._units': 225}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4104 - root_mean_squared_error: 1.1876 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2112\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5074 - root_mean_squared_error: 0.7123 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1884\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1838 - root_mean_squared_error: 0.4287 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1846\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1230 - root_mean_squared_error: 0.3507 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1845\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1062 - root_mean_squared_error: 0.3259 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1855\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1009 - root_mean_squared_error: 0.3176 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1868\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0992 - root_mean_squared_error: 0.3149 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1883\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0986 - root_mean_squared_error: 0.3140 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1898\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0984 - root_mean_squared_error: 0.3137 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1914\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0983 - root_mean_squared_error: 0.3136 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1946\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1962\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1978\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0405 - val_root_mean_squared_error: 0.2013\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2048\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2085\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2103\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2123\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2142\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2162\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0476 - val_root_mean_squared_error: 0.2182\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0485 - val_root_mean_squared_error: 0.2203\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0495 - val_root_mean_squared_error: 0.2225\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0504 - val_root_mean_squared_error: 0.2246\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0514 - val_root_mean_squared_error: 0.2268\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2289\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0534 - val_root_mean_squared_error: 0.2311\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0544 - val_root_mean_squared_error: 0.2333\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0555 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0983 - root_mean_squared_error: 0.3135 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029F310AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:02:58,693]\u001b[0m Trial 126 finished with value: 0.18449462404446582 and parameters: {'step': 2, 'no._units': 249}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8456 - root_mean_squared_error: 0.9196 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1822\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2931 - root_mean_squared_error: 0.5414 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0739 - root_mean_squared_error: 0.2719 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0503 - root_mean_squared_error: 0.2243 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0450 - root_mean_squared_error: 0.2120 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0434 - root_mean_squared_error: 0.2083 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0429 - root_mean_squared_error: 0.2071 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - root_mean_squared_error: 0.2067 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0427 - root_mean_squared_error: 0.2066 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - root_mean_squared_error: 0.2065 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1409\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1411\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1442\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1446\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1450\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1454\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1458\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1462\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1466\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1475\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1479\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - root_mean_squared_error: 0.2065 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1492\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C0981700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:00,342]\u001b[0m Trial 127 finished with value: 0.13947226445069044 and parameters: {'step': 2, 'no._units': 235}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8356 - root_mean_squared_error: 0.9141 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0213 - root_mean_squared_error: 0.1461 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0140 - root_mean_squared_error: 0.1185 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1085 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - root_mean_squared_error: 0.1035 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1031 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1029 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1237\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1270\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1321\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1358\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1407\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202852A1C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:01,874]\u001b[0m Trial 128 finished with value: 0.11663750702754888 and parameters: {'step': 2, 'no._units': 229}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9397 - root_mean_squared_error: 0.9694 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2139\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0924 - root_mean_squared_error: 0.3040 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2072\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0391 - root_mean_squared_error: 0.1977 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2021\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2002\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0244 - root_mean_squared_error: 0.1561 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2000\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - root_mean_squared_error: 0.1525 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2004\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0229 - root_mean_squared_error: 0.1513 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1509 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2019\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0411 - val_root_mean_squared_error: 0.2028\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2036\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2054\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2097\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2106\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2123\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0454 - val_root_mean_squared_error: 0.2131\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2139\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2147\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0465 - val_root_mean_squared_error: 0.2156\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2164\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2172\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0475 - val_root_mean_squared_error: 0.2180\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0479 - val_root_mean_squared_error: 0.2188\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0483 - val_root_mean_squared_error: 0.2197\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2205\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2214\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2222\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2230\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0501 - val_root_mean_squared_error: 0.2238\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0504 - val_root_mean_squared_error: 0.2246\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BEB0B550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:03,460]\u001b[0m Trial 129 finished with value: 0.2000264162721403 and parameters: {'step': 2, 'no._units': 260}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5948 - root_mean_squared_error: 0.7713 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2034\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2810 - root_mean_squared_error: 0.5301 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0861 - root_mean_squared_error: 0.2934 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0653 - root_mean_squared_error: 0.2556 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0600 - root_mean_squared_error: 0.2450 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0584 - root_mean_squared_error: 0.2416 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1553\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0578 - root_mean_squared_error: 0.2405 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - root_mean_squared_error: 0.2401 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2400 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - root_mean_squared_error: 0.2400 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1564\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1572\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1589\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1603\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1611\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1619\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1628\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1637\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0271 - val_root_mean_squared_error: 0.1647\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1658\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1693\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1720\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1798\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - root_mean_squared_error: 0.2399 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1834\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C7B35310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:05,089]\u001b[0m Trial 130 finished with value: 0.155321218124702 and parameters: {'step': 2, 'no._units': 213}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6412 - root_mean_squared_error: 1.2811 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - root_mean_squared_error: 0.2601 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - root_mean_squared_error: 0.1664 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1387 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1358 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC3CA1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:06,556]\u001b[0m Trial 131 finished with value: 0.09217407652265272 and parameters: {'step': 2, 'no._units': 447}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7259 - root_mean_squared_error: 0.8520 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1768\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0601 - root_mean_squared_error: 0.2451 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1635\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0327 - root_mean_squared_error: 0.1809 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0252 - root_mean_squared_error: 0.1589 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0221 - root_mean_squared_error: 0.1488 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0219 - root_mean_squared_error: 0.1479 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1476 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1534\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1542\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1548\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1575\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1597\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1602\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C77DA160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:08,532]\u001b[0m Trial 132 finished with value: 0.15321784152125542 and parameters: {'step': 2, 'no._units': 220}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7388 - root_mean_squared_error: 0.8595 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1806\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3335 - root_mean_squared_error: 0.5775 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - root_mean_squared_error: 0.1548 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1722\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1306 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1243 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0148 - root_mean_squared_error: 0.1216 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1678\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1213 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1213 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1640\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1627\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1600\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1585\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1475\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1427\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1411\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1363\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1209\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1341\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1370\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0147 - root_mean_squared_error: 0.1212 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1631\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029F8FD790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:11,842]\u001b[0m Trial 133 finished with value: 0.10155493458225556 and parameters: {'step': 2, 'no._units': 400}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.9739 - root_mean_squared_error: 0.9869 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1798 - root_mean_squared_error: 0.4240 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0385 - root_mean_squared_error: 0.1963 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - root_mean_squared_error: 0.1559 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0235 - root_mean_squared_error: 0.1532 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - root_mean_squared_error: 0.1523 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1520 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1519 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1599\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1616\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1624\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1633\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1641\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1658\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1722\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D08D4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:13,410]\u001b[0m Trial 134 finished with value: 0.14870589905780665 and parameters: {'step': 2, 'no._units': 284}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9091 - root_mean_squared_error: 0.9535 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1434\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1308 - root_mean_squared_error: 0.3617 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0387 - root_mean_squared_error: 0.1967 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0305 - root_mean_squared_error: 0.1748 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0282 - root_mean_squared_error: 0.1680 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0274 - root_mean_squared_error: 0.1656 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0272 - root_mean_squared_error: 0.1648 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0271 - root_mean_squared_error: 0.1646 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1645 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0555\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0541\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0527\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0512\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0498\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0483\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0440\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0426\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0412\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 9.9962e-04 - val_root_mean_squared_error: 0.0316\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 9.2539e-04 - val_root_mean_squared_error: 0.0304\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 8.5866e-04 - val_root_mean_squared_error: 0.0293\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 7.9986e-04 - val_root_mean_squared_error: 0.0283\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 7.4936e-04 - val_root_mean_squared_error: 0.0274\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 7.0729e-04 - val_root_mean_squared_error: 0.0266\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 6.7419e-04 - val_root_mean_squared_error: 0.0260\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 6.5052e-04 - val_root_mean_squared_error: 0.0255\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 6.3674e-04 - val_root_mean_squared_error: 0.0252\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 6.3336e-04 - val_root_mean_squared_error: 0.0252\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 6.4085e-04 - val_root_mean_squared_error: 0.0253\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 6.5929e-04 - val_root_mean_squared_error: 0.0257\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 6.8964e-04 - val_root_mean_squared_error: 0.0263\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 7.3220e-04 - val_root_mean_squared_error: 0.0271\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 7.8818e-04 - val_root_mean_squared_error: 0.0281\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 8.5814e-04 - val_root_mean_squared_error: 0.0293\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 9.4268e-04 - val_root_mean_squared_error: 0.0307\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0323\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0424\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0448\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0473\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0498\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0525\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0552\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0580\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D0E0F940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:17,021]\u001b[0m Trial 135 finished with value: 0.02516669528313718 and parameters: {'step': 2, 'no._units': 246}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6000 - root_mean_squared_error: 0.7746 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1339 - root_mean_squared_error: 0.3659 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0344 - root_mean_squared_error: 0.1856 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0237 - root_mean_squared_error: 0.1538 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - root_mean_squared_error: 0.1444 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0200 - root_mean_squared_error: 0.1413 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1399 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1398 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0804\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0858\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B8E15C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:19,715]\u001b[0m Trial 136 finished with value: 0.07698102693414798 and parameters: {'step': 2, 'no._units': 241}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5243 - root_mean_squared_error: 0.7241 - val_loss: 0.0674 - val_root_mean_squared_error: 0.2595\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0788 - root_mean_squared_error: 0.2806 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0181 - root_mean_squared_error: 0.1347 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1643\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0134 - root_mean_squared_error: 0.1160 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1611\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0122 - root_mean_squared_error: 0.1105 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1600\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0118 - root_mean_squared_error: 0.1087 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1595\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1079 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1078 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1589\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1078 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1078 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1585\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1078 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1582\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1576\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1572\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1564\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1524\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1521\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1508\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1482\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1474\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1456\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1452\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1446\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1436\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1454\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1460\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1467\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1474\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1575\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1629\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1648\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1711\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1803\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1827\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AED141F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:23,617]\u001b[0m Trial 137 finished with value: 0.14363514351143056 and parameters: {'step': 2, 'no._units': 229}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7441 - root_mean_squared_error: 0.8626 - val_loss: 0.0545 - val_root_mean_squared_error: 0.2334\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0293 - root_mean_squared_error: 0.1711 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0139 - root_mean_squared_error: 0.1178 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - root_mean_squared_error: 0.1026 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - root_mean_squared_error: 0.0973 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1727\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - root_mean_squared_error: 0.0949 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - root_mean_squared_error: 0.0946 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0946 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1786\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1833\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1848\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1864\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1880\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1897\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1914\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1930\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1948\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0386 - val_root_mean_squared_error: 0.1965\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1983\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2001\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0407 - val_root_mean_squared_error: 0.2018\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2036\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2053\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0444 - val_root_mean_squared_error: 0.2107\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2145\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0476 - val_root_mean_squared_error: 0.2182\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BBE3C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:25,163]\u001b[0m Trial 138 finished with value: 0.1703683657591465 and parameters: {'step': 2, 'no._units': 259}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1522 - root_mean_squared_error: 1.0734 - val_loss: 0.0525 - val_root_mean_squared_error: 0.2290\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1878 - root_mean_squared_error: 0.4334 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0435 - root_mean_squared_error: 0.2087 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0304 - root_mean_squared_error: 0.1745 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0272 - root_mean_squared_error: 0.1648 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0261 - root_mean_squared_error: 0.1617 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0258 - root_mean_squared_error: 0.1607 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1603 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1012\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0257 - root_mean_squared_error: 0.1602 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1271\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020290ACEEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:28,666]\u001b[0m Trial 139 finished with value: 0.09629032416102486 and parameters: {'step': 2, 'no._units': 268}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6131 - root_mean_squared_error: 0.7830 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1760 - root_mean_squared_error: 0.4195 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0372 - root_mean_squared_error: 0.1930 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0274 - root_mean_squared_error: 0.1655 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0250 - root_mean_squared_error: 0.1581 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0242 - root_mean_squared_error: 0.1557 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - root_mean_squared_error: 0.1549 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1547 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1546 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1231\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A9CDFEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:30,210]\u001b[0m Trial 140 finished with value: 0.11384196145035531 and parameters: {'step': 2, 'no._units': 248}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4945 - root_mean_squared_error: 0.7032 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0928 - root_mean_squared_error: 0.3046 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - root_mean_squared_error: 0.1369 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - root_mean_squared_error: 0.1170 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - root_mean_squared_error: 0.1127 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - root_mean_squared_error: 0.1115 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1597\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1605\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1622\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1631\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1641\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1660\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1679\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1699\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1719\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1760\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1769\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1789\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1799\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1809\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1818\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C060D5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:31,680]\u001b[0m Trial 141 finished with value: 0.12963760218612244 and parameters: {'step': 2, 'no._units': 186}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5361 - root_mean_squared_error: 1.2394 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0511 - root_mean_squared_error: 0.2261 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - root_mean_squared_error: 0.1804 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0259 - root_mean_squared_error: 0.1608 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - root_mean_squared_error: 0.1536 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1501 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE9B3940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:33,175]\u001b[0m Trial 142 finished with value: 0.11539286282024071 and parameters: {'step': 2, 'no._units': 409}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9109 - root_mean_squared_error: 0.9544 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2395\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1422 - root_mean_squared_error: 0.3771 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0786 - root_mean_squared_error: 0.2804 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1687\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0630 - root_mean_squared_error: 0.2510 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0582 - root_mean_squared_error: 0.2413 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1688\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0567 - root_mean_squared_error: 0.2380 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1696\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0561 - root_mean_squared_error: 0.2370 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0560 - root_mean_squared_error: 0.2366 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2365 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1736\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1768\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1779\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1790\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1812\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1823\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1835\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1847\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1859\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1872\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1885\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1898\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1912\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0371 - val_root_mean_squared_error: 0.1926\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1956\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1988\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2005\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2023\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C5235160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:34,742]\u001b[0m Trial 143 finished with value: 0.1681980574376797 and parameters: {'step': 2, 'no._units': 203}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8538 - root_mean_squared_error: 1.6893 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0908 - root_mean_squared_error: 0.3013 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - root_mean_squared_error: 0.1231 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - root_mean_squared_error: 0.1177 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0133 - root_mean_squared_error: 0.1152 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1135 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - root_mean_squared_error: 0.1134 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1209\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1214\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1313\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1317\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202903FDE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:36,270]\u001b[0m Trial 144 finished with value: 0.11062233277309379 and parameters: {'step': 2, 'no._units': 490}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3478 - root_mean_squared_error: 0.5898 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2021\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1772 - root_mean_squared_error: 0.4210 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1353\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0221 - root_mean_squared_error: 0.1488 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0175 - root_mean_squared_error: 0.1323 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0169 - root_mean_squared_error: 0.1302 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0169 - root_mean_squared_error: 0.1300 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1290\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1302\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC4E1550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:38,067]\u001b[0m Trial 145 finished with value: 0.12501314246648965 and parameters: {'step': 2, 'no._units': 215}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.1061 - root_mean_squared_error: 1.4512 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1907 - root_mean_squared_error: 0.4367 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0104 - root_mean_squared_error: 0.1018 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1482\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1477\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1473\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1469\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1460\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1456\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1452\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1413\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1328\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1323\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1318\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1303\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1284\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1269\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1284\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1358\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1444\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1582\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1609\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1636\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1664\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029361CCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:41,556]\u001b[0m Trial 146 finished with value: 0.1256125381067641 and parameters: {'step': 2, 'no._units': 432}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.4260 - root_mean_squared_error: 1.5576 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0524 - root_mean_squared_error: 0.2288 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - root_mean_squared_error: 0.1374 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1333 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1319 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0865\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0765\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0820\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A5C75700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:44,654]\u001b[0m Trial 147 finished with value: 0.07253061800299371 and parameters: {'step': 2, 'no._units': 500}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0071 - root_mean_squared_error: 1.0035 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0735 - root_mean_squared_error: 0.2711 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0404 - root_mean_squared_error: 0.2011 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1668\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - root_mean_squared_error: 0.1761 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1673\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1686\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0267 - root_mean_squared_error: 0.1634 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - root_mean_squared_error: 0.1630 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1732\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1765\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1858\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1878\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1898\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1919\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1939\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1981\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0401 - val_root_mean_squared_error: 0.2003\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2024\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2067\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2110\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2133\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2155\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2200\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0494 - val_root_mean_squared_error: 0.2222\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - root_mean_squared_error: 0.1629 - val_loss: 0.0504 - val_root_mean_squared_error: 0.2245\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CE0B5DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:46,192]\u001b[0m Trial 148 finished with value: 0.16677866438388367 and parameters: {'step': 2, 'no._units': 302}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6254 - root_mean_squared_error: 0.7908 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0328 - root_mean_squared_error: 0.1810 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0107 - root_mean_squared_error: 0.1033 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0086 - root_mean_squared_error: 0.0927 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0077 - root_mean_squared_error: 0.0876 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1158\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1124\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - root_mean_squared_error: 0.0869 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D260A670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:49,182]\u001b[0m Trial 149 finished with value: 0.10850970261265286 and parameters: {'step': 2, 'no._units': 225}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4698 - root_mean_squared_error: 1.5715 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1852 - root_mean_squared_error: 0.4303 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0521 - root_mean_squared_error: 0.2283 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0313 - root_mean_squared_error: 0.1770 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - root_mean_squared_error: 0.1510 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1219\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - root_mean_squared_error: 0.1240 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1237\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - root_mean_squared_error: 0.1228 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0150 - root_mean_squared_error: 0.1225 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0150 - root_mean_squared_error: 0.1224 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - root_mean_squared_error: 0.1223 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1223 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1269\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1279\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1303\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1222 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1317\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029361CEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:51,585]\u001b[0m Trial 150 finished with value: 0.10399791144499163 and parameters: {'step': 4, 'no._units': 464}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.5305 - root_mean_squared_error: 1.5907 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2896 - root_mean_squared_error: 0.5381 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0392 - root_mean_squared_error: 0.1979 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - root_mean_squared_error: 0.1443 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - root_mean_squared_error: 0.1271 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - root_mean_squared_error: 0.1259 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0158 - root_mean_squared_error: 0.1255 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1254 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.1253 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BEB0BD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:53,081]\u001b[0m Trial 151 finished with value: 0.08162955074717775 and parameters: {'step': 2, 'no._units': 499}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6810 - root_mean_squared_error: 1.6374 - val_loss: 0.0538 - val_root_mean_squared_error: 0.2320\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7016 - root_mean_squared_error: 0.8376 - val_loss: 0.0390 - val_root_mean_squared_error: 0.1976\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0847 - root_mean_squared_error: 0.2910 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - root_mean_squared_error: 0.2160 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1977\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0396 - root_mean_squared_error: 0.1991 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1982\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1986\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1991\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0370 - root_mean_squared_error: 0.1923 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2000\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2005\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2010\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2014\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2019\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2024\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2029\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2035\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2046\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2051\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2057\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2078\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2086\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2101\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2109\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2117\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0456 - val_root_mean_squared_error: 0.2135\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2144\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2153\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - root_mean_squared_error: 0.1922 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002016C0764C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:54,622]\u001b[0m Trial 152 finished with value: 0.19704546527376487 and parameters: {'step': 2, 'no._units': 479}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6951 - root_mean_squared_error: 1.3020 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3476 - root_mean_squared_error: 0.5895 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0568\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0966 - root_mean_squared_error: 0.3108 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0710 - root_mean_squared_error: 0.2664 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - root_mean_squared_error: 0.2539 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0625 - root_mean_squared_error: 0.2500 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0618 - root_mean_squared_error: 0.2487 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0616 - root_mean_squared_error: 0.2483 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0616 - root_mean_squared_error: 0.2481 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2481 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - root_mean_squared_error: 0.2480 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC3CA820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:56,122]\u001b[0m Trial 153 finished with value: 0.056773759402399274 and parameters: {'step': 2, 'no._units': 418}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6314 - root_mean_squared_error: 1.2773 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2448 - root_mean_squared_error: 0.4948 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0705 - root_mean_squared_error: 0.2655 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1380\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1366\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0440 - root_mean_squared_error: 0.2097 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0414 - root_mean_squared_error: 0.2035 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0412 - root_mean_squared_error: 0.2030 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2028 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1388\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1418\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1424\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1444\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1485\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1492\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1519\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A5C75700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:03:57,758]\u001b[0m Trial 154 finished with value: 0.13650026447315378 and parameters: {'step': 2, 'no._units': 415}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.0940 - root_mean_squared_error: 1.4471 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1195 - root_mean_squared_error: 0.3457 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0293 - root_mean_squared_error: 0.1711 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0205 - root_mean_squared_error: 0.1431 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1398 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002027BAB7DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:01,010]\u001b[0m Trial 155 finished with value: 0.09439994058432971 and parameters: {'step': 2, 'no._units': 441}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6812 - root_mean_squared_error: 1.2966 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - root_mean_squared_error: 0.2406 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0366 - root_mean_squared_error: 0.1913 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0316 - root_mean_squared_error: 0.1778 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0290 - root_mean_squared_error: 0.1703 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0287 - root_mean_squared_error: 0.1693 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0820\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0682\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0677\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0660\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0644\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0682\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4F47790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:04,037]\u001b[0m Trial 156 finished with value: 0.06415793162128698 and parameters: {'step': 2, 'no._units': 391}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5429 - root_mean_squared_error: 1.2421 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0661 - root_mean_squared_error: 0.2572 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - root_mean_squared_error: 0.1776 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - root_mean_squared_error: 0.1527 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0227 - root_mean_squared_error: 0.1505 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1495 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1130\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - root_mean_squared_error: 0.1494 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020292015280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:07,190]\u001b[0m Trial 157 finished with value: 0.09532641684045415 and parameters: {'step': 2, 'no._units': 391}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5656 - root_mean_squared_error: 1.2512 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3002 - root_mean_squared_error: 0.5479 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - root_mean_squared_error: 0.2578 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0448 - root_mean_squared_error: 0.2116 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1416\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0397 - root_mean_squared_error: 0.1991 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - root_mean_squared_error: 0.1953 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1448\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0375 - root_mean_squared_error: 0.1936 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1935 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1469\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1476\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1514\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1531\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1550\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1603\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1614\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1626\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1639\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1651\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1664\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1677\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AE9B3DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:08,661]\u001b[0m Trial 158 finished with value: 0.10311118592896991 and parameters: {'step': 2, 'no._units': 373}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3715 - root_mean_squared_error: 1.1711 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0764 - root_mean_squared_error: 0.2765 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - root_mean_squared_error: 0.2069 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0354 - root_mean_squared_error: 0.1881 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0331 - root_mean_squared_error: 0.1819 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0323 - root_mean_squared_error: 0.1798 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - root_mean_squared_error: 0.1791 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1544\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - root_mean_squared_error: 0.1788 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - root_mean_squared_error: 0.1788 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1525\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1502\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1500\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1492\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1488\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1485\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1485\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1485\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1486\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202998B1AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:10,129]\u001b[0m Trial 159 finished with value: 0.13549466930156534 and parameters: {'step': 2, 'no._units': 332}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1493 - root_mean_squared_error: 1.4660 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2531 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - root_mean_squared_error: 0.1484 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0200 - root_mean_squared_error: 0.1415 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0194 - root_mean_squared_error: 0.1393 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - root_mean_squared_error: 0.1385 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D08D40D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:11,599]\u001b[0m Trial 160 finished with value: 0.06168730984546183 and parameters: {'step': 2, 'no._units': 421}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1103 - root_mean_squared_error: 1.0537 - val_loss: 0.0517 - val_root_mean_squared_error: 0.2274\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5352 - root_mean_squared_error: 0.7316 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1623\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0948 - root_mean_squared_error: 0.3080 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1610\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0750 - root_mean_squared_error: 0.2739 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1617\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - root_mean_squared_error: 0.2606 - val_loss: 0.0265 - val_root_mean_squared_error: 0.1628\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0654 - root_mean_squared_error: 0.2557 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1640\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - root_mean_squared_error: 0.2540 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - root_mean_squared_error: 0.2534 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1723\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1755\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1771\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1789\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1806\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1824\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1862\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1881\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1901\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1921\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1942\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0394 - val_root_mean_squared_error: 0.1985\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0403 - val_root_mean_squared_error: 0.2007\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2053\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2077\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2101\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - root_mean_squared_error: 0.2532 - val_loss: 0.0463 - val_root_mean_squared_error: 0.2152\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CAEA10D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:13,126]\u001b[0m Trial 161 finished with value: 0.16102978752088062 and parameters: {'step': 2, 'no._units': 423}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7726 - root_mean_squared_error: 1.3314 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0895 - root_mean_squared_error: 0.2992 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0321 - root_mean_squared_error: 0.1792 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0226 - root_mean_squared_error: 0.1504 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0197 - root_mean_squared_error: 0.1405 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0188 - root_mean_squared_error: 0.1370 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0184 - root_mean_squared_error: 0.1357 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1353 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0183 - root_mean_squared_error: 0.1351 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - root_mean_squared_error: 0.1351 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B8E15310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:15,495]\u001b[0m Trial 162 finished with value: 0.09616100927778436 and parameters: {'step': 2, 'no._units': 404}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9101 - root_mean_squared_error: 0.9540 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7269 - root_mean_squared_error: 0.8526 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2010 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - root_mean_squared_error: 0.1638 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0243 - root_mean_squared_error: 0.1559 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0235 - root_mean_squared_error: 0.1534 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0233 - root_mean_squared_error: 0.1526 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1524 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1523 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0820\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0765\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - root_mean_squared_error: 0.1522 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D0EDC4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:18,323]\u001b[0m Trial 163 finished with value: 0.07479896779626878 and parameters: {'step': 2, 'no._units': 416}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0617 - root_mean_squared_error: 1.4359 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2009\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0461 - root_mean_squared_error: 0.2148 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1710\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0261 - root_mean_squared_error: 0.1617 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0220 - root_mean_squared_error: 0.1482 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1648\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - root_mean_squared_error: 0.1435 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1654\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0199 - root_mean_squared_error: 0.1412 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1660\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0199 - root_mean_squared_error: 0.1410 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0199 - root_mean_squared_error: 0.1409 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1673\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1687\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1717\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1725\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1759\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1775\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1791\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1799\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1807\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1815\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1823\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1831\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1848\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1856\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1864\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - root_mean_squared_error: 0.1409 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1873\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CAD8C3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:20,884]\u001b[0m Trial 164 finished with value: 0.16480899884695285 and parameters: {'step': 2, 'no._units': 409}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7873 - root_mean_squared_error: 1.3369 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1508\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - root_mean_squared_error: 0.0939 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1542\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0844 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1550\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - root_mean_squared_error: 0.0805 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0784 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1531\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1474\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1359\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1351\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1342\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1319\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1311\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1279\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1259\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1248\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1231\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1219\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BF284A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:25,568]\u001b[0m Trial 165 finished with value: 0.10049153956177949 and parameters: {'step': 2, 'no._units': 430}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3810 - root_mean_squared_error: 1.1752 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1498\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0539 - root_mean_squared_error: 0.2322 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0132 - root_mean_squared_error: 0.1150 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1216\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0106 - root_mean_squared_error: 0.1028 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1115\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0804\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1351\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1387\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029F8FD430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:28,907]\u001b[0m Trial 166 finished with value: 0.07941879715149466 and parameters: {'step': 2, 'no._units': 350}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8229 - root_mean_squared_error: 1.6801 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1732 - root_mean_squared_error: 0.4162 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0728 - root_mean_squared_error: 0.2699 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1823\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0532 - root_mean_squared_error: 0.2306 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0475 - root_mean_squared_error: 0.2181 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1837\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0457 - root_mean_squared_error: 0.2139 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0451 - root_mean_squared_error: 0.2124 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1835\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0449 - root_mean_squared_error: 0.2120 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1833\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0449 - root_mean_squared_error: 0.2118 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1826\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1824\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1822\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1818\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1815\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1813\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1810\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1805\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1803\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1800\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1798\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1796\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1793\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1791\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1788\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1786\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1783\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202AFEFFDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:30,329]\u001b[0m Trial 167 finished with value: 0.1560791588874558 and parameters: {'step': 2, 'no._units': 419}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.9066 - root_mean_squared_error: 0.9522 - val_loss: 0.0697 - val_root_mean_squared_error: 0.2639\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2122 - root_mean_squared_error: 1.1010 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1919\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0994 - root_mean_squared_error: 0.3152 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1850\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0599 - root_mean_squared_error: 0.2448 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0527 - root_mean_squared_error: 0.2296 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1850\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0507 - root_mean_squared_error: 0.2252 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1862\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0501 - root_mean_squared_error: 0.2238 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1876\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0499 - root_mean_squared_error: 0.2233 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1891\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1906\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1922\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1938\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1955\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1989\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0403 - val_root_mean_squared_error: 0.2007\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2025\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2044\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2063\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2082\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2102\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2122\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2143\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2164\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2185\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2207\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2230\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2252\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0518 - val_root_mean_squared_error: 0.2275\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0528 - val_root_mean_squared_error: 0.2298\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0540 - val_root_mean_squared_error: 0.2323\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0551 - val_root_mean_squared_error: 0.2348\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2374\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - root_mean_squared_error: 0.2231 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C77DA310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:31,863]\u001b[0m Trial 168 finished with value: 0.18421728309723184 and parameters: {'step': 2, 'no._units': 395}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7846 - root_mean_squared_error: 0.8858 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0829 - root_mean_squared_error: 0.2879 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0261 - root_mean_squared_error: 0.1616 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1401 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - root_mean_squared_error: 0.1319 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1430\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1434\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1436\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CB15E430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:33,328]\u001b[0m Trial 169 finished with value: 0.11893115317426012 and parameters: {'step': 2, 'no._units': 314}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4898 - root_mean_squared_error: 1.2206 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0608 - root_mean_squared_error: 0.2466 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0260 - root_mean_squared_error: 0.1612 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0236 - root_mean_squared_error: 0.1537 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0228 - root_mean_squared_error: 0.1511 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0225 - root_mean_squared_error: 0.1499 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1498 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0671\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0593\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0583\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0573\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0562\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0552\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0541\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0530\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0519\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0508\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0497\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0486\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0474\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0463\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0451\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0440\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0428\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0417\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0394\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0331\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0322\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 9.8285e-04 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 9.3644e-04 - val_root_mean_squared_error: 0.0306\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.9661e-04 - val_root_mean_squared_error: 0.0299\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.6367e-04 - val_root_mean_squared_error: 0.0294\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.3798e-04 - val_root_mean_squared_error: 0.0289\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.1986e-04 - val_root_mean_squared_error: 0.0286\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.0965e-04 - val_root_mean_squared_error: 0.0285\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.0777e-04 - val_root_mean_squared_error: 0.0284\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.1451e-04 - val_root_mean_squared_error: 0.0285\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.3006e-04 - val_root_mean_squared_error: 0.0288\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.5469e-04 - val_root_mean_squared_error: 0.0292\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 8.8865e-04 - val_root_mean_squared_error: 0.0298\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 9.3216e-04 - val_root_mean_squared_error: 0.0305\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 9.8539e-04 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0324\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0335\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0389\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0421\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0438\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0490\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0508\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0526\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0563\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0600\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028DA67160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:37,318]\u001b[0m Trial 170 finished with value: 0.028421264992133044 and parameters: {'step': 2, 'no._units': 399}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9424 - root_mean_squared_error: 1.3937 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3027 - root_mean_squared_error: 0.5502 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0519 - root_mean_squared_error: 0.2278 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0303 - root_mean_squared_error: 0.1741 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - root_mean_squared_error: 0.1709 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - root_mean_squared_error: 0.1696 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1407\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1423\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1439\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1451\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1476\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1520\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - root_mean_squared_error: 0.1694 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1565\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C90FC9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:38,749]\u001b[0m Trial 171 finished with value: 0.09583470147884562 and parameters: {'step': 2, 'no._units': 399}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7328 - root_mean_squared_error: 1.3164 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2120\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1388 - root_mean_squared_error: 0.3726 - val_loss: 0.0595 - val_root_mean_squared_error: 0.2439\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0430 - root_mean_squared_error: 0.2074 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2504\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0361 - root_mean_squared_error: 0.1899 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2515\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - root_mean_squared_error: 0.1852 - val_loss: 0.0631 - val_root_mean_squared_error: 0.2513\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0337 - root_mean_squared_error: 0.1837 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2508\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0336 - root_mean_squared_error: 0.1832 - val_loss: 0.0626 - val_root_mean_squared_error: 0.2502\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0623 - val_root_mean_squared_error: 0.2495\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2489\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2482\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2475\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2469\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2462\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0602 - val_root_mean_squared_error: 0.2455\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2440\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2433\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2426\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0585 - val_root_mean_squared_error: 0.2419\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2411\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0578 - val_root_mean_squared_error: 0.2404\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2397\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0571 - val_root_mean_squared_error: 0.2389\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2382\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0560 - val_root_mean_squared_error: 0.2367\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0550 - val_root_mean_squared_error: 0.2345\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2337\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2330\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C5235280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:40,177]\u001b[0m Trial 172 finished with value: 0.21201438245973478 and parameters: {'step': 2, 'no._units': 403}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6511 - root_mean_squared_error: 1.2849 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2656 - root_mean_squared_error: 0.5153 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1608\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0532 - root_mean_squared_error: 0.2306 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1656\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1665\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0242 - root_mean_squared_error: 0.1557 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - root_mean_squared_error: 0.1501 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - root_mean_squared_error: 0.1483 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - root_mean_squared_error: 0.1477 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - root_mean_squared_error: 0.1475 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1666\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1668\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1671\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1672\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1674\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1678\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1680\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1686\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1699\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1715\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1722\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1736\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC4E1280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:41,634]\u001b[0m Trial 173 finished with value: 0.12375445766641131 and parameters: {'step': 2, 'no._units': 384}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7049 - root_mean_squared_error: 1.3057 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1002 - root_mean_squared_error: 0.3165 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0397 - root_mean_squared_error: 0.1992 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0295 - root_mean_squared_error: 0.1717 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0267 - root_mean_squared_error: 0.1633 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0258 - root_mean_squared_error: 0.1605 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0665\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0255 - root_mean_squared_error: 0.1595 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0254 - root_mean_squared_error: 0.1592 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0602\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0586\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0578\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0572\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0570\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0568\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0567\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0568\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0571\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0573\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0576\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0579\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0584\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0600\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0620\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0654\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0682\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A5C75820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:44,022]\u001b[0m Trial 174 finished with value: 0.05673778921181689 and parameters: {'step': 2, 'no._units': 410}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9124 - root_mean_squared_error: 1.3829 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7183 - root_mean_squared_error: 0.8475 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1895\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1361 - root_mean_squared_error: 0.3689 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0885 - root_mean_squared_error: 0.2975 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0781 - root_mean_squared_error: 0.2794 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1778\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0750 - root_mean_squared_error: 0.2739 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1782\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0740 - root_mean_squared_error: 0.2721 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1788\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0737 - root_mean_squared_error: 0.2715 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1795\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2713 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1803\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2713 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1810\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2713 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1819\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1837\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1846\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1856\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1867\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1891\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0367 - val_root_mean_squared_error: 0.1915\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1928\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1953\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1967\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0398 - val_root_mean_squared_error: 0.1994\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0403 - val_root_mean_squared_error: 0.2009\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2023\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2038\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2053\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2069\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2101\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2117\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0736 - root_mean_squared_error: 0.2712 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2134\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020297D5A0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:45,655]\u001b[0m Trial 175 finished with value: 0.17781962999899395 and parameters: {'step': 2, 'no._units': 425}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1701 - root_mean_squared_error: 1.4731 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2884 - root_mean_squared_error: 0.5370 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0390 - root_mean_squared_error: 0.1975 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0250 - root_mean_squared_error: 0.1581 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0222 - root_mean_squared_error: 0.1491 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0215 - root_mean_squared_error: 0.1465 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1457 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1454 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1359\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1369\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1380\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1390\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1423\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0209 - val_root_mean_squared_error: 0.1447\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B5DB09D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:47,081]\u001b[0m Trial 176 finished with value: 0.1223557531139455 and parameters: {'step': 2, 'no._units': 388}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.9230 - root_mean_squared_error: 0.9607 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0518 - root_mean_squared_error: 0.2276 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1624\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - root_mean_squared_error: 0.1333 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - root_mean_squared_error: 0.1160 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1833\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1854\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0119 - root_mean_squared_error: 0.1091 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1863\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - root_mean_squared_error: 0.1085 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1869\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1083 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1874\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1083 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1878\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1083 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1882\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1887\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1891\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1895\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1900\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1904\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0365 - val_root_mean_squared_error: 0.1909\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1914\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1919\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1925\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1930\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1936\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1946\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1952\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1957\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0385 - val_root_mean_squared_error: 0.1961\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1966\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0389 - val_root_mean_squared_error: 0.1972\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1977\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1982\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1987\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CF5940D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:48,524]\u001b[0m Trial 177 finished with value: 0.12232754030922989 and parameters: {'step': 2, 'no._units': 231}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5908 - root_mean_squared_error: 1.2613 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2453\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7618 - root_mean_squared_error: 0.8728 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2348 - root_mean_squared_error: 0.4846 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1479\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1754 - root_mean_squared_error: 0.4188 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1598 - root_mean_squared_error: 0.3997 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1548 - root_mean_squared_error: 0.3934 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1502\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1531 - root_mean_squared_error: 0.3913 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1516\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1526 - root_mean_squared_error: 0.3906 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1524 - root_mean_squared_error: 0.3904 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1595\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1633\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1673\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1695\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1717\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1790\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1870\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1898\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1928\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1988\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2020\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2085\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2119\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1523 - root_mean_squared_error: 0.3903 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2154\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D58C1CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:50,045]\u001b[0m Trial 178 finished with value: 0.14793251518899544 and parameters: {'step': 2, 'no._units': 433}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 1.4873 - root_mean_squared_error: 1.2195 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1337\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0772 - root_mean_squared_error: 0.2778 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0219 - root_mean_squared_error: 0.1479 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0189 - root_mean_squared_error: 0.1373 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - root_mean_squared_error: 0.1364 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1361 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1360 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1360 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1360 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1053\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - root_mean_squared_error: 0.1359 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202852A1430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:54,316]\u001b[0m Trial 179 finished with value: 0.09707374690759435 and parameters: {'step': 2, 'no._units': 414}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8051 - root_mean_squared_error: 1.3436 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3930 - root_mean_squared_error: 0.6269 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0724 - root_mean_squared_error: 0.2690 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0465 - root_mean_squared_error: 0.2156 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2010 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - root_mean_squared_error: 0.1964 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0380 - root_mean_squared_error: 0.1949 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1526\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1519\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1500\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1488\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0220 - val_root_mean_squared_error: 0.1482\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1477\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0216 - val_root_mean_squared_error: 0.1470\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1450\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1436\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0204 - val_root_mean_squared_error: 0.1430\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1423\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1416\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1393\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1385\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1369\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202920158B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:55,750]\u001b[0m Trial 180 finished with value: 0.10269140845261338 and parameters: {'step': 2, 'no._units': 448}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7657 - root_mean_squared_error: 1.3288 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1622 - root_mean_squared_error: 0.4027 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0365 - root_mean_squared_error: 0.1910 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0264 - root_mean_squared_error: 0.1624 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0238 - root_mean_squared_error: 0.1543 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - root_mean_squared_error: 0.1516 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1504 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1503 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - root_mean_squared_error: 0.1502 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B8E15700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:57,213]\u001b[0m Trial 181 finished with value: 0.07908854569756063 and parameters: {'step': 2, 'no._units': 420}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8474 - root_mean_squared_error: 1.3592 - val_loss: 0.0752 - val_root_mean_squared_error: 0.2743\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2610 - root_mean_squared_error: 0.5109 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1102 - root_mean_squared_error: 0.3319 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0819 - root_mean_squared_error: 0.2861 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2327\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0739 - root_mean_squared_error: 0.2719 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2317\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0714 - root_mean_squared_error: 0.2673 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2314\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0706 - root_mean_squared_error: 0.2657 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2312\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0703 - root_mean_squared_error: 0.2652 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2312\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2650 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2313\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2650 - val_loss: 0.0535 - val_root_mean_squared_error: 0.2313\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2650 - val_loss: 0.0536 - val_root_mean_squared_error: 0.2315\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0536 - val_root_mean_squared_error: 0.2316\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2318\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0538 - val_root_mean_squared_error: 0.2320\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0539 - val_root_mean_squared_error: 0.2321\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0540 - val_root_mean_squared_error: 0.2324\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2326\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2329\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0544 - val_root_mean_squared_error: 0.2333\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2336\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2340\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0549 - val_root_mean_squared_error: 0.2344\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0551 - val_root_mean_squared_error: 0.2348\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0555 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0558 - val_root_mean_squared_error: 0.2362\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0560 - val_root_mean_squared_error: 0.2367\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0563 - val_root_mean_squared_error: 0.2373\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2379\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2385\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0572 - val_root_mean_squared_error: 0.2391\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0575 - val_root_mean_squared_error: 0.2398\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0579 - val_root_mean_squared_error: 0.2405\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2413\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2420\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2428\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0593 - val_root_mean_squared_error: 0.2436\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - root_mean_squared_error: 0.2649 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2444\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202995FA9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:04:58,883]\u001b[0m Trial 182 finished with value: 0.2312257498870975 and parameters: {'step': 2, 'no._units': 404}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4260 - root_mean_squared_error: 1.5576 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0532 - root_mean_squared_error: 0.2307 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - root_mean_squared_error: 0.1133 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1056 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0104 - root_mean_squared_error: 0.1021 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - root_mean_squared_error: 0.1006 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - root_mean_squared_error: 0.1000 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - root_mean_squared_error: 0.0998 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0858\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0579\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0564\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0548\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0533\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0500\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0483\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0466\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0449\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0396\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0323\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 9.2875e-04 - val_root_mean_squared_error: 0.0305\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 8.2507e-04 - val_root_mean_squared_error: 0.0287\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 7.3130e-04 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 6.4842e-04 - val_root_mean_squared_error: 0.0255\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 5.7769e-04 - val_root_mean_squared_error: 0.0240\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 5.1991e-04 - val_root_mean_squared_error: 0.0228\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 4.7622e-04 - val_root_mean_squared_error: 0.0218\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 4.4782e-04 - val_root_mean_squared_error: 0.0212\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 4.3596e-04 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 4.4197e-04 - val_root_mean_squared_error: 0.0210\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 4.6718e-04 - val_root_mean_squared_error: 0.0216\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 5.1358e-04 - val_root_mean_squared_error: 0.0227\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 5.8257e-04 - val_root_mean_squared_error: 0.0241\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 6.7522e-04 - val_root_mean_squared_error: 0.0260\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 7.9305e-04 - val_root_mean_squared_error: 0.0282\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 9.3752e-04 - val_root_mean_squared_error: 0.0306\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0333\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0393\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0425\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0459\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0530\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0567\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0605\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0682\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202B33778B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:02,365]\u001b[0m Trial 183 finished with value: 0.02087970077846279 and parameters: {'step': 2, 'no._units': 394}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6297 - root_mean_squared_error: 1.2766 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2248\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1958 - root_mean_squared_error: 0.4425 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2185\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0469 - root_mean_squared_error: 0.2166 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2109\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0324 - root_mean_squared_error: 0.1799 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2082\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0283 - root_mean_squared_error: 0.1682 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2072\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0270 - root_mean_squared_error: 0.1642 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2068\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0265 - root_mean_squared_error: 0.1628 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2067\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0264 - root_mean_squared_error: 0.1623 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0263 - root_mean_squared_error: 0.1622 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2067\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2067\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2068\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2068\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2069\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2070\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2072\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2073\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2074\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2076\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2077\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2078\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2079\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2082\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2085\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2086\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2087\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2088\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2088\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - root_mean_squared_error: 0.1621 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC6B49D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:04,108]\u001b[0m Trial 184 finished with value: 0.20656639732416276 and parameters: {'step': 2, 'no._units': 394}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9272 - root_mean_squared_error: 1.3882 - val_loss: 0.1132 - val_root_mean_squared_error: 0.3365\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3477 - root_mean_squared_error: 0.5897 - val_loss: 0.0967 - val_root_mean_squared_error: 0.3110\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0630 - root_mean_squared_error: 0.2509 - val_loss: 0.0920 - val_root_mean_squared_error: 0.3032\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0450 - root_mean_squared_error: 0.2122 - val_loss: 0.0907 - val_root_mean_squared_error: 0.3011\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0905 - val_root_mean_squared_error: 0.3008\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - root_mean_squared_error: 0.1998 - val_loss: 0.0907 - val_root_mean_squared_error: 0.3012\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0395 - root_mean_squared_error: 0.1988 - val_loss: 0.0911 - val_root_mean_squared_error: 0.3018\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0394 - root_mean_squared_error: 0.1985 - val_loss: 0.0915 - val_root_mean_squared_error: 0.3025\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1984 - val_loss: 0.0920 - val_root_mean_squared_error: 0.3033\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0925 - val_root_mean_squared_error: 0.3041\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0929 - val_root_mean_squared_error: 0.3049\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0935 - val_root_mean_squared_error: 0.3057\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0940 - val_root_mean_squared_error: 0.3066\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0945 - val_root_mean_squared_error: 0.3075\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0951 - val_root_mean_squared_error: 0.3084\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0957 - val_root_mean_squared_error: 0.3093\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0963 - val_root_mean_squared_error: 0.3103\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0969 - val_root_mean_squared_error: 0.3112\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0974 - val_root_mean_squared_error: 0.3122\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0980 - val_root_mean_squared_error: 0.3131\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0986 - val_root_mean_squared_error: 0.3140\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0992 - val_root_mean_squared_error: 0.3150\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0999 - val_root_mean_squared_error: 0.3160\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1005 - val_root_mean_squared_error: 0.3170\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1012 - val_root_mean_squared_error: 0.3181\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1018 - val_root_mean_squared_error: 0.3191\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1025 - val_root_mean_squared_error: 0.3202\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1032 - val_root_mean_squared_error: 0.3212\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1039 - val_root_mean_squared_error: 0.3223\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1046 - val_root_mean_squared_error: 0.3234\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1053 - val_root_mean_squared_error: 0.3245\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1060 - val_root_mean_squared_error: 0.3256\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1067 - val_root_mean_squared_error: 0.3267\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1074 - val_root_mean_squared_error: 0.3278\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.1082 - val_root_mean_squared_error: 0.3289\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BBD40820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:05,667]\u001b[0m Trial 185 finished with value: 0.3007751578366674 and parameters: {'step': 2, 'no._units': 409}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4329 - root_mean_squared_error: 1.5598 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2460\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4964 - root_mean_squared_error: 0.7046 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2164\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1385 - root_mean_squared_error: 0.3721 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0796 - root_mean_squared_error: 0.2821 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2035\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0645 - root_mean_squared_error: 0.2540 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0599 - root_mean_squared_error: 0.2447 - val_loss: 0.0413 - val_root_mean_squared_error: 0.2031\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0584 - root_mean_squared_error: 0.2416 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2035\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0579 - root_mean_squared_error: 0.2406 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - root_mean_squared_error: 0.2403 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2046\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - root_mean_squared_error: 0.2401 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2051\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - root_mean_squared_error: 0.2401 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2057\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2068\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2074\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2086\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2098\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2104\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2110\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2116\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2123\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0454 - val_root_mean_squared_error: 0.2130\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0456 - val_root_mean_squared_error: 0.2137\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2144\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0463 - val_root_mean_squared_error: 0.2151\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2158\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0469 - val_root_mean_squared_error: 0.2165\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2172\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0475 - val_root_mean_squared_error: 0.2179\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0481 - val_root_mean_squared_error: 0.2193\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2200\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2207\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2401 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2213\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202ABB66F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:07,234]\u001b[0m Trial 186 finished with value: 0.20297612152645175 and parameters: {'step': 2, 'no._units': 381}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7552 - root_mean_squared_error: 1.3249 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1101 - root_mean_squared_error: 0.3318 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1341\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0552 - root_mean_squared_error: 0.2349 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1383\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0382 - root_mean_squared_error: 0.1955 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1386\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0370 - root_mean_squared_error: 0.1923 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1386\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - root_mean_squared_error: 0.1912 - val_loss: 0.0192 - val_root_mean_squared_error: 0.1384\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0364 - root_mean_squared_error: 0.1908 - val_loss: 0.0191 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0364 - root_mean_squared_error: 0.1907 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1376\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1370\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0186 - val_root_mean_squared_error: 0.1363\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1359\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1351\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1341\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1336\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1302\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1289\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1269\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1256\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1207\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1311\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1332\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1355\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1462\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1525\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1595\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1710\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1751\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1793\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028AE37550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:10,064]\u001b[0m Trial 187 finished with value: 0.1181720762906195 and parameters: {'step': 2, 'no._units': 363}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7283 - root_mean_squared_error: 1.3147 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1508\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2289 - root_mean_squared_error: 0.4784 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0453 - root_mean_squared_error: 0.2127 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1495\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0271 - root_mean_squared_error: 0.1647 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0229 - root_mean_squared_error: 0.1512 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1525\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - root_mean_squared_error: 0.1470 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1528\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - root_mean_squared_error: 0.1456 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1530\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - root_mean_squared_error: 0.1451 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1532\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1450 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1548\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1576\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1594\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1598\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1602\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1611\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CF79EB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:11,521]\u001b[0m Trial 188 finished with value: 0.1441007851209267 and parameters: {'step': 2, 'no._units': 396}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.8738 - root_mean_squared_error: 0.9348 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2250\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0883 - root_mean_squared_error: 0.2971 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2396\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2159 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2451\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2467\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - root_mean_squared_error: 0.1866 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2470\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2468\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0336 - root_mean_squared_error: 0.1832 - val_loss: 0.0607 - val_root_mean_squared_error: 0.2463\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2459\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1828 - val_loss: 0.0602 - val_root_mean_squared_error: 0.2454\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1828 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2448\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2443\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0594 - val_root_mean_squared_error: 0.2438\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2432\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2421\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2416\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2411\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0579 - val_root_mean_squared_error: 0.2406\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2395\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0571 - val_root_mean_squared_error: 0.2390\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2385\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0562 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0559 - val_root_mean_squared_error: 0.2364\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0551 - val_root_mean_squared_error: 0.2347\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0548 - val_root_mean_squared_error: 0.2342\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2336\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202C4CE98B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:12,940]\u001b[0m Trial 189 finished with value: 0.22498695530372484 and parameters: {'step': 2, 'no._units': 241}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6709 - root_mean_squared_error: 1.6343 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2877 - root_mean_squared_error: 0.5364 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0898 - root_mean_squared_error: 0.2997 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - root_mean_squared_error: 0.2613 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0623 - root_mean_squared_error: 0.2495 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0603 - root_mean_squared_error: 0.2455 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0596 - root_mean_squared_error: 0.2442 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0594 - root_mean_squared_error: 0.2437 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2436 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0815\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - root_mean_squared_error: 0.2435 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202BEB0B280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:14,357]\u001b[0m Trial 190 finished with value: 0.07844524392752583 and parameters: {'step': 2, 'no._units': 439}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9503 - root_mean_squared_error: 1.3965 - val_loss: 0.0643 - val_root_mean_squared_error: 0.2536\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4970 - root_mean_squared_error: 0.7050 - val_loss: 0.0375 - val_root_mean_squared_error: 0.1937\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0685 - root_mean_squared_error: 0.2616 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1818\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0420 - root_mean_squared_error: 0.2049 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1787\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - root_mean_squared_error: 0.1891 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0354 - root_mean_squared_error: 0.1880 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1784\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1877 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1788\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1876 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1792\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1797\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1813\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1820\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1826\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1833\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1846\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1854\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1862\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1870\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1888\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1898\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1908\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0372 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1940\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1952\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0386 - val_root_mean_squared_error: 0.1964\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0391 - val_root_mean_squared_error: 0.1977\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0396 - val_root_mean_squared_error: 0.1990\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0402 - val_root_mean_squared_error: 0.2004\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2019\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0414 - val_root_mean_squared_error: 0.2034\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202A42A8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:15,903]\u001b[0m Trial 191 finished with value: 0.17797709908472917 and parameters: {'step': 2, 'no._units': 415}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.0035 - root_mean_squared_error: 1.4155 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0943 - root_mean_squared_error: 0.3071 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0298 - root_mean_squared_error: 0.1728 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0237 - root_mean_squared_error: 0.1539 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - root_mean_squared_error: 0.1479 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0213 - root_mean_squared_error: 0.1458 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1451 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - root_mean_squared_error: 0.1448 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - root_mean_squared_error: 0.1447 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CAEA1EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:17,362]\u001b[0m Trial 192 finished with value: 0.08959026446901595 and parameters: {'step': 2, 'no._units': 404}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8023 - root_mean_squared_error: 1.3425 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2426\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2300 - root_mean_squared_error: 0.4795 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1947\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0541 - root_mean_squared_error: 0.2325 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1869\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0362 - root_mean_squared_error: 0.1902 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1840\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0317 - root_mean_squared_error: 0.1782 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0304 - root_mean_squared_error: 0.1743 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1823\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0300 - root_mean_squared_error: 0.1731 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1819\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0298 - root_mean_squared_error: 0.1727 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0298 - root_mean_squared_error: 0.1725 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1814\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1725 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1811\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1809\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1806\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1805\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1804\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1803\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1801\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1803\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0325 - val_root_mean_squared_error: 0.1804\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1806\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0328 - val_root_mean_squared_error: 0.1810\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1813\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1821\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1825\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1835\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1847\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1853\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1860\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0349 - val_root_mean_squared_error: 0.1868\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1876\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1885\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0359 - val_root_mean_squared_error: 0.1894\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1913\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0370 - val_root_mean_squared_error: 0.1923\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0374 - val_root_mean_squared_error: 0.1934\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0379 - val_root_mean_squared_error: 0.1946\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0383 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1970\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1983\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0399 - val_root_mean_squared_error: 0.1996\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D720EAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:19,376]\u001b[0m Trial 193 finished with value: 0.18013170919901994 and parameters: {'step': 2, 'no._units': 429}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.5180 - root_mean_squared_error: 0.7197 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1352\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1529 - root_mean_squared_error: 0.3910 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0537 - root_mean_squared_error: 0.2318 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0804\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0409 - root_mean_squared_error: 0.2024 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0371 - root_mean_squared_error: 0.1925 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - root_mean_squared_error: 0.1892 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0354 - root_mean_squared_error: 0.1881 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1877 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1876 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1132\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1151\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002028D848DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:21,791]\u001b[0m Trial 194 finished with value: 0.0775191469258212 and parameters: {'step': 2, 'no._units': 221}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9541 - root_mean_squared_error: 1.3979 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1548\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2145 - root_mean_squared_error: 0.4631 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - root_mean_squared_error: 0.2540 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1546\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0526 - root_mean_squared_error: 0.2294 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0492 - root_mean_squared_error: 0.2218 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0480 - root_mean_squared_error: 0.2191 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0476 - root_mean_squared_error: 0.2182 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0475 - root_mean_squared_error: 0.2178 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1564\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1565\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1572\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1580\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1597\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1602\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1613\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1619\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D08D4C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:23,253]\u001b[0m Trial 195 finished with value: 0.150452891307837 and parameters: {'step': 2, 'no._units': 421}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7095 - root_mean_squared_error: 1.3075 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2120\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2206 - root_mean_squared_error: 0.4696 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1674\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0566 - root_mean_squared_error: 0.2379 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0451 - root_mean_squared_error: 0.2124 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0420 - root_mean_squared_error: 0.2050 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1548\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0410 - root_mean_squared_error: 0.2026 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0407 - root_mean_squared_error: 0.2018 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1548\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0406 - root_mean_squared_error: 0.2015 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1549\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0406 - root_mean_squared_error: 0.2014 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1550\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1553\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1559\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1560\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1564\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1565\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1576\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1579\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0250 - val_root_mean_squared_error: 0.1581\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1585\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0405 - root_mean_squared_error: 0.2014 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202CC2D5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:24,859]\u001b[0m Trial 196 finished with value: 0.15472353030190283 and parameters: {'step': 2, 'no._units': 410}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4204 - root_mean_squared_error: 1.1918 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1443\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3099 - root_mean_squared_error: 0.5567 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1123 - root_mean_squared_error: 0.3351 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0863 - root_mean_squared_error: 0.2937 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0584\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0787 - root_mean_squared_error: 0.2805 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0592\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0762 - root_mean_squared_error: 0.2760 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0754 - root_mean_squared_error: 0.2745 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0751 - root_mean_squared_error: 0.2740 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0750 - root_mean_squared_error: 0.2738 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0627\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0750 - root_mean_squared_error: 0.2738 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2738 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0695\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - root_mean_squared_error: 0.2737 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020292015B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:26,353]\u001b[0m Trial 197 finished with value: 0.05753498197110653 and parameters: {'step': 2, 'no._units': 391}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2094 - root_mean_squared_error: 1.0997 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1893 - root_mean_squared_error: 0.4350 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0532 - root_mean_squared_error: 0.2307 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0371 - root_mean_squared_error: 0.1927 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0329 - root_mean_squared_error: 0.1814 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0312 - root_mean_squared_error: 0.1765 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0310 - root_mean_squared_error: 0.1761 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0310 - root_mean_squared_error: 0.1760 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1164\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1198\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1217\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1311\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - root_mean_squared_error: 0.1759 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1373\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000202D5F5D280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:28,270]\u001b[0m Trial 198 finished with value: 0.1158920513313193 and parameters: {'step': 2, 'no._units': 376}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7091 - root_mean_squared_error: 0.8421 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1279 - root_mean_squared_error: 0.3576 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0318 - root_mean_squared_error: 0.1785 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - root_mean_squared_error: 0.1508 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0205 - root_mean_squared_error: 0.1432 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - root_mean_squared_error: 0.1407 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1068\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - root_mean_squared_error: 0.1398 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0899\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0671\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0644\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0654\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1343\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1388\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1478\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0194 - root_mean_squared_error: 0.1394 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002029676C3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-27 18:05:31,706]\u001b[0m Trial 199 finished with value: 0.06391297700452425 and parameters: {'step': 2, 'no._units': 254}. Best is trial 66 with value: 0.01615077453765188.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score\n",
    "best_error = np.inf\n",
    "best_study_score, best_study_params = study_func(X_train, y_train, X_val, y_val, objective_wrappper_keras_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "divided-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Val_rmse for the study is:  0.01615077453765188\n"
     ]
    }
   ],
   "source": [
    "print('The best Val_rmse for the study is: ',best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bizarre-litigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best study parameters for the classifier are:  {'step': 3, 'no._units': 209}\n"
     ]
    }
   ],
   "source": [
    "print('The best study parameters for the classifier are: ',best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "perfect-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best Neural Network\n",
    "Best_Model_eq = keras.models.load_model('Best_model_Selu_eq_Learn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "configured-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_591\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_591 (Bat (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1191 (Dense)           (None, 209)               1254      \n",
      "_________________________________________________________________\n",
      "dense_1192 (Dense)           (None, 1)                 210       \n",
      "=================================================================\n",
      "Total params: 1,484\n",
      "Trainable params: 1,474\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Printing its summary\n",
    "Best_Model_eq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "preliminary-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag_5</th>\n",
       "      <th>Lag_4</th>\n",
       "      <th>Lag_3</th>\n",
       "      <th>Lag_2</th>\n",
       "      <th>Lag_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>-0.086230</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.193209</td>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.193209</td>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>0.193209</td>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>-0.092897</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.117007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>-0.029432</td>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.117007</td>\n",
       "      <td>0.121464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.117007</td>\n",
       "      <td>0.121464</td>\n",
       "      <td>0.073344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Lag_5     Lag_4     Lag_3     Lag_2     Lag_1\n",
       "Date                                                        \n",
       "2019-04-01 -0.086230  0.026412  0.193209 -0.092897 -0.029432\n",
       "2019-05-01  0.026412  0.193209 -0.092897 -0.029432  0.021367\n",
       "2019-06-01  0.193209 -0.092897 -0.029432  0.021367  0.044184\n",
       "2019-07-01 -0.092897 -0.029432  0.021367  0.044184 -0.117007\n",
       "2019-08-01 -0.029432  0.021367  0.044184 -0.117007  0.121464\n",
       "2019-09-01  0.021367  0.044184 -0.117007  0.121464  0.073344"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the test features\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "motivated-representative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>0.021367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>0.044184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>-0.117007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>0.121464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>0.073344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>-0.070441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Vol\n",
       "Date                \n",
       "2019-04-01  0.021367\n",
       "2019-05-01  0.044184\n",
       "2019-06-01 -0.117007\n",
       "2019-07-01  0.121464\n",
       "2019-08-01  0.073344\n",
       "2019-09-01 -0.070441"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  printing the test response variable\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sixth-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the predicted values for the response variable\n",
    "y_pred = Best_Model_eq.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "wanted-algebra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03409936],\n",
       "       [-0.04255687],\n",
       "       [ 0.00885888],\n",
       "       [ 0.32942876],\n",
       "       [ 0.09208167],\n",
       "       [-0.18181185]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "polyphonic-portrait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2016-10-01    5.608215\n",
       "2016-11-01    5.462154\n",
       "2016-12-01    5.460531\n",
       "2017-01-01    5.561825\n",
       "2017-02-01    5.612089\n",
       "2017-03-01    5.626469\n",
       "2017-04-01    5.542273\n",
       "2017-05-01    5.611150\n",
       "2017-06-01    5.524882\n",
       "2017-07-01    5.675093\n",
       "2017-08-01    5.673933\n",
       "2017-09-01    5.721613\n",
       "2017-10-01    5.587717\n",
       "2017-11-01    5.681674\n",
       "2017-12-01    5.696307\n",
       "2018-01-01    5.734474\n",
       "2018-02-01    5.608913\n",
       "2018-03-01    5.676979\n",
       "2018-04-01    5.709079\n",
       "2018-05-01    5.726844\n",
       "2018-06-01    5.645628\n",
       "2018-07-01    5.757587\n",
       "2018-08-01    5.787137\n",
       "2018-09-01    5.729019\n",
       "2018-10-01    5.779478\n",
       "2018-11-01    5.693248\n",
       "2018-12-01    5.719660\n",
       "2019-01-01    5.912869\n",
       "2019-02-01    5.819972\n",
       "2019-03-01    5.790540\n",
       "2019-04-01    5.811906\n",
       "2019-05-01    5.856091\n",
       "2019-06-01    5.739084\n",
       "2019-07-01    5.860547\n",
       "2019-08-01    5.933891\n",
       "2019-09-01    5.863451\n",
       "Name: Vol, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the bis_log series\n",
    "bis_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "czech-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03409936, -0.04255687,  0.00885888,  0.32942876,  0.09208167,\n",
       "       -0.18181185], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "attractive-enzyme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02136678,  0.04418432, -0.11700702,  0.12146362,  0.07334404,\n",
       "       -0.07044066])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "arabic-tuition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.790539704243972"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bis_log.loc['2019-03-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cloudy-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_log_rmse(v, y_true, y_pred):\n",
    "    ''' Calculates rmse between true and predicted time series values & returns rmse , log true val &\n",
    "    log predicted values.\n",
    "    y_true: array of true diff_log_series\n",
    "    y_pred: array of predicted diff_log_series\n",
    "    v: Previous time true log_series value '''\n",
    "    y_tr = []\n",
    "    y_pr = []\n",
    "    val_tr = v\n",
    "    val_pr = v\n",
    "    for i in range(len(y_true)):\n",
    "        y_tr.append(y_true[i]+val_tr)\n",
    "        y_pr.append(y_pred[i]+val_pr)\n",
    "        val_tr = y_true[i]+val_tr\n",
    "        val_pr = y_pred[i]+val_pr\n",
    "    return sqrt(mean_squared_error(y_tr,y_pr)) , y_tr, y_pr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "quiet-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set log_bis rmse, log_bis test set & log_bis test set predicted values are returned.\n",
    "rmse_log_bis , y_tr_ls, y_pr_ls = true_log_rmse(bis_log.loc['2019-03-01'],y_test.values.flatten(),y_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "intellectual-respect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.811906484620068,\n",
       " 5.856090800238491,\n",
       " 5.739083785107921,\n",
       " 5.8605474058266,\n",
       " 5.933891444095732,\n",
       " 5.863450779674508]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "champion-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of the log_bis test set rmse using MLP Neural net is: 0.17386972625335095\n"
     ]
    }
   ],
   "source": [
    "print('The value of the log_bis test set rmse using MLP Neural net is: ',rmse_log_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "scheduled-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.824639063309267,\n",
       " 5.7820821925805355,\n",
       " 5.790941069814696,\n",
       " 6.120369832012191,\n",
       " 6.212451505455508,\n",
       " 6.03063965121223]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pr_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-harvest",
   "metadata": {},
   "source": [
    "### Observations: \n",
    "### 1) From the above analysis we can clearly that the test set rmse of the log_bis series for the MLP Neural net around 9 times the corresponding figure for the best SARIMA model with config \"[(0, 0, 0), (0, 1, 0, 12), 'c']\". which is not surprising considering that Classical linear model tends to beat Neural Nets on the univariate time series forecasting.\n",
    "### 2) Another reason for the abysmally  low Neural Net rmse is that Neural nets tend to perform better when the dataset is fairly large. here we just had 20 observations in the Training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-grill",
   "metadata": {},
   "source": [
    "### Fitting the Neural Net with best configuration on the whole data set in order to predict next 6 values for next six months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "finite-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the original diff_log_bis observations into training & val set\n",
    "X_train, X_val = X.iloc[:25], X.iloc[25:]\n",
    "y_train, y_val = y.iloc[:25], y.iloc[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "architectural-congress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "endless-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompiling the the best model\n",
    "Best_Model_eq.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Nadam(beta_1=0.9, beta_2=0.999)\n",
    "                      ,metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "leading-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function that controls the learning rate.\n",
    "def exponential_decay_fn(epoch): # \n",
    "            return 0.01 * 0.1**(epoch /best_study_params['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "specialized-native",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5679 - root_mean_squared_error: 0.7536 - val_loss: 0.0214 - val_root_mean_squared_error: 0.1464\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0591 - root_mean_squared_error: 0.2431 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0351 - root_mean_squared_error: 0.1872 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0256 - root_mean_squared_error: 0.1600 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - root_mean_squared_error: 0.1490 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - root_mean_squared_error: 0.1440 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0201 - root_mean_squared_error: 0.1417 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - root_mean_squared_error: 0.1405 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - root_mean_squared_error: 0.1400 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1208\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1237\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1357\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0193 - val_root_mean_squared_error: 0.1388\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1453\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0231 - val_root_mean_squared_error: 0.1521\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1661\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2648dd37550>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the checkpoints\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('Best_Model_eq_bis.h5',save_best_only=True) # 1st Callback\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=30,restore_best_weights=True) # 2nd Callback, Stop if validation score doen't improve for\n",
    "        # 30 epochs        \n",
    "lr_scheduler_cb = keras.callbacks.LearningRateScheduler(exponential_decay_fn)# 3rd Callback\n",
    "        \n",
    "        #Refitting the best model\n",
    "Best_Model_eq.fit(X_train, y_train, epochs=200, validation_data=(X_val,y_val), batch_size=5,\n",
    "             callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler_cb], shuffle=False)# Shuffle is false so \n",
    "# that model trains on observations that are trained on chronological observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-victor",
   "metadata": {},
   "source": [
    "### Observations: \n",
    "### 1) From the above output it is evident that is  validation set rmse has reduced to .0907( 25 training observations) from .17 (20 training observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-constitutional",
   "metadata": {},
   "source": [
    "### Forecasting next 6 monthly values in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "unknown-knight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2016-11-01   -0.146061\n",
       "2016-12-01   -0.001623\n",
       "2017-01-01    0.101295\n",
       "2017-02-01    0.050263\n",
       "2017-03-01    0.014381\n",
       "2017-04-01   -0.084196\n",
       "2017-05-01    0.068877\n",
       "2017-06-01   -0.086267\n",
       "2017-07-01    0.150211\n",
       "2017-08-01   -0.001160\n",
       "2017-09-01    0.047680\n",
       "2017-10-01   -0.133896\n",
       "2017-11-01    0.093957\n",
       "2017-12-01    0.014633\n",
       "2018-01-01    0.038167\n",
       "2018-02-01   -0.125561\n",
       "2018-03-01    0.068066\n",
       "2018-04-01    0.032099\n",
       "2018-05-01    0.017765\n",
       "2018-06-01   -0.081216\n",
       "2018-07-01    0.111959\n",
       "2018-08-01    0.029550\n",
       "2018-09-01   -0.058118\n",
       "2018-10-01    0.050459\n",
       "2018-11-01   -0.086230\n",
       "2018-12-01    0.026412\n",
       "2019-01-01    0.193209\n",
       "2019-02-01   -0.092897\n",
       "2019-03-01   -0.029432\n",
       "2019-04-01    0.021367\n",
       "2019-05-01    0.044184\n",
       "2019-06-01   -0.117007\n",
       "2019-07-01    0.121464\n",
       "2019-08-01    0.073344\n",
       "2019-09-01   -0.070441\n",
       "Name: Vol, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bis_log_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "informed-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the newly trained best Neural net\n",
    "Best_Model_eq = keras.models.load_model('Best_Model_eq_bis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "revised-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_591\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_591 (Bat (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1191 (Dense)           (None, 209)               1254      \n",
      "_________________________________________________________________\n",
      "dense_1192 (Dense)           (None, 1)                 210       \n",
      "=================================================================\n",
      "Total params: 1,484\n",
      "Trainable params: 1,474\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Best_Model_eq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "closing-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_future_vals(series, no_val, model):\n",
    "    ''' forecasts number of values no_val, in the future through model \n",
    "    for the given last stationary observations series '''\n",
    "    preds = []\n",
    "    lags = len(series)\n",
    "    X = [x for x in series.values]\n",
    "    for i in range(no_val):\n",
    "        arr = np.array(X).reshape(-1,lags)\n",
    "        preds.append(model.predict(arr).flatten()[0])# model.predict() gives arrays\n",
    "        X.append(preds[-1])\n",
    "        X = X[-lags:]\n",
    "    return preds        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-earth",
   "metadata": {},
   "source": [
    "### Forecasting the next six monthly values of the bis_log_diff series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "organizational-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting last 5 value from the bis_log_diff series\n",
    "s_l_5 = bis_log_diff.iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "senior-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting forecasts\n",
    "y_diff_preds = forecast_future_vals(s_l_5, 6, Best_Model_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "quick-plastic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.085968e-05, -0.11999405, 0.11164963, 0.06948024, -0.09487402, 0.050575856]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_diff_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "annoying-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts 1 differenced diff_log series to log series\n",
    "def convert_to_log(last_val,diff_log):\n",
    "    '''Converts 1 differenced diff_log series to log series\n",
    "    diff_log : array of 1 differenced diff_log_series\n",
    "    prev_val : previous log_val\n",
    "    '''\n",
    "    log_val = []\n",
    "    for i in range(len(diff_log)):\n",
    "        log_val.append(diff_log[i]+last_val)\n",
    "        last_val = log_val[-1]\n",
    "        \n",
    "    return log_val        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "heated-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_bis_forecast=convert_to_log(bis_log.iloc[-1],y_diff_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "colonial-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.863521639352598,\n",
       " 5.743527587598123,\n",
       " 5.855177220052042,\n",
       " 5.924657460397043,\n",
       " 5.829783443456449,\n",
       " 5.880359299575844]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Six forecasted values of the log_bis series\n",
    "y_log_bis_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "protecting-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the datetime index\n",
    "index = pd.date_range(start='2019-10-1',periods=6,freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "surrounded-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the forecasted values to the pandas series\n",
    "forecast = pd.Series(y_log_bis_forecast,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "suspended-workplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-10-01    5.863522\n",
       "2019-11-01    5.743528\n",
       "2019-12-01    5.855177\n",
       "2020-01-01    5.924657\n",
       "2020-02-01    5.829783\n",
       "2020-03-01    5.880359\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "detected-workshop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the original & forecasted values of the log_bis series\n",
    "# Displaying the True & Predicted values of the biscuit series\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(bis_log,color='green',label='log_bis_series')\n",
    "plt.plot(forecast,color='red',marker='+',label='Neural forecasted_log_bis_series')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('log(biscuit_vol)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-pitch",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "### 1) The test set rmse of our tuned MLP model = 0.1738697, which is much more than the baseline rmse of 0.0512311 (corresponding to best naive model) and hence our MLP Neural Net  doesn't  seem to have any predictive power on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-laugh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
